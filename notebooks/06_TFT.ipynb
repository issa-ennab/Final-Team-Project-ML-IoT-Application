{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer (TFT) Attempt\n",
    "\n",
    "### Why We Considered It:\n",
    "- TFT is a **state-of-the-art deep learning model** for **sequential data forecasting**.\n",
    "- It integrates **multiple time-series features** and **handles long-range dependencies** better than traditional RNN-based models (LSTM/GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_forecasting\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "MPS Available: True\n",
      "MPS Built: True\n",
      "Using device: mps\n",
      "PyTorch Forecasting Installed: Success\n",
      "PyTorch Lightning Version: 2.5.0.post0\n"
     ]
    }
   ],
   "source": [
    "# Print PyTorch version\n",
    "print(torch.__version__)\n",
    "\n",
    "# Check if Apple Metal GPU backend (MPS) is available\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "print(\"MPS Built:\", torch.backends.mps.is_built())\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"PyTorch Forecasting Installed:\", \"Success\" if 'pytorch_forecasting' in dir() else \"Failed\")\n",
    "print(\"PyTorch Lightning Version:\", pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080905, 81)\n",
      "      timestamp  acc_x_dashboard_left  acc_y_dashboard_left  \\\n",
      "0  1.577219e+09              0.365116              0.167893   \n",
      "1  1.577219e+09              0.392649              0.176273   \n",
      "2  1.577219e+09              0.409408              0.181062   \n",
      "3  1.577219e+09              0.371101              0.164302   \n",
      "4  1.577219e+09              0.390255              0.159514   \n",
      "\n",
      "   acc_z_dashboard_left  acc_x_above_suspension_left  \\\n",
      "0              9.793961                     0.327626   \n",
      "1              9.771216                     0.381496   \n",
      "2              9.732909                     0.283333   \n",
      "3              9.749668                     0.314458   \n",
      "4              9.869378                     0.344385   \n",
      "\n",
      "   acc_y_above_suspension_left  acc_z_above_suspension_left  \\\n",
      "0                     0.172733                     9.781861   \n",
      "1                     0.189492                     9.699261   \n",
      "2                     0.182310                     9.807000   \n",
      "3                     0.230194                     9.739963   \n",
      "4                     0.202660                     9.762708   \n",
      "\n",
      "   acc_x_below_suspension_left  acc_y_below_suspension_left  \\\n",
      "0                     0.024797                     0.172611   \n",
      "1                     0.024797                     0.194158   \n",
      "2                     0.003249                     0.227677   \n",
      "3                     0.005643                     0.172611   \n",
      "4                     0.005643                     0.200144   \n",
      "\n",
      "   acc_z_below_suspension_left  ...  speed_bump_cobblestone  good_road_left  \\\n",
      "0                     9.793824  ...                       0               1   \n",
      "1                     9.842905  ...                       0               1   \n",
      "2                     9.888395  ...                       0               1   \n",
      "3                     9.871635  ...                       0               1   \n",
      "4                     9.860862  ...                       0               1   \n",
      "\n",
      "   regular_road_left  bad_road_left  good_road_right  regular_road_right  \\\n",
      "0                  0              0                1                   0   \n",
      "1                  0              0                1                   0   \n",
      "2                  0              0                1                   0   \n",
      "3                  0              0                1                   0   \n",
      "4                  0              0                1                   0   \n",
      "\n",
      "   bad_road_right  experiment_id             vehicle    scenario  \n",
      "0               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "1               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "2               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "3               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "4               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned master dataset\n",
    "df = pd.read_csv('dataset/cleaned_master_dataset.csv')\n",
    "\n",
    "# Quick check\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some EDA here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ex: Quick EDA - Visualize vibration data or vehicle-specific trends\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x='scenario', y='acc_x_dashboard_left', data=df)\n",
    "plt.title('Dashboard Acceleration X by Scenario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Starting Data Preprocessing...\n",
      "✔️ Timestamp dtype: int64\n",
      "\n",
      "🔹 Splitting Data...\n",
      "\n",
      "🔹 Filtering sequences shorter than required length...\n",
      "✅ After filtering: 864724 training rows, 216181 validation rows\n",
      "\n",
      "🔹 Checking unique sequence lengths per vehicle...\n",
      "count       3.000000\n",
      "mean     2884.000000\n",
      "std      1393.818137\n",
      "min      1276.000000\n",
      "25%      2452.500000\n",
      "50%      3629.000000\n",
      "75%      3688.000000\n",
      "max      3747.000000\n",
      "Name: timestamp, dtype: float64\n",
      "count       1.0\n",
      "mean     2164.0\n",
      "std         NaN\n",
      "min      2164.0\n",
      "25%      2164.0\n",
      "50%      2164.0\n",
      "75%      2164.0\n",
      "max      2164.0\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "🔹 Checking for empty columns in train and validation sets...\n",
      "❌ Empty columns in train set: ['activity']\n",
      "❌ Empty columns in validation set: ['activity']\n",
      "🚀 Removing empty column 'activity' from train and validation sets.\n",
      "\n",
      "🔹 Checking if `time_varying_unknown_reals` columns contain data...\n",
      "🔹 acc_x_dashboard_left - Missing values: 0 / 864724\n",
      "🔹 acc_y_dashboard_left - Missing values: 0 / 864724\n",
      "\n",
      "🔹 Checking for empty sequences before creating TimeSeriesDataSet...\n",
      "❌ Empty sequences in training set: 0\n",
      "❌ Empty sequences in validation set: 0\n",
      "\n",
      "🔹 Creating TimeSeriesDataSet for training & validation...\n",
      "\n",
      "✅ Final dataset sizes:\n",
      "📊 Train dataset size: 851585\n",
      "📊 Validation dataset size: 211387\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer, NaNLabelEncoder\n",
    "\n",
    "# 📌 1. DATA PREPROCESSING\n",
    "print(\"🔹 Starting Data Preprocessing...\")\n",
    "\n",
    "# ✅ Copy original dataset to avoid modifications\n",
    "master_df = df.copy()\n",
    "\n",
    "# ✅ Convert timestamp to integer index\n",
    "master_df[\"timestamp\"] = master_df[\"timestamp\"].astype(int)\n",
    "\n",
    "# ✅ Handle missing values in target column\n",
    "master_df[\"speed_meters_per_second\"] = master_df[\"speed_meters_per_second\"].ffill().bfill()\n",
    "\n",
    "# ✅ Ensure vehicle column has no missing values\n",
    "master_df[\"vehicle\"] = master_df[\"vehicle\"].fillna(\"unknown\")\n",
    "\n",
    "# ✅ Print timestamp dtype for verification\n",
    "print(f\"✔️ Timestamp dtype: {master_df['timestamp'].dtype}\")  # Should print 'int64'\n",
    "\n",
    "# 📌 2. SPLITTING DATA INTO TRAIN & VALIDATION\n",
    "print(\"\\n🔹 Splitting Data...\")\n",
    "\n",
    "# ✅ Define time series parameters\n",
    "max_prediction_length = 5  # Future steps to predict\n",
    "max_encoder_length = 15  # History length\n",
    "\n",
    "# ✅ Split dataset manually (80% train, 20% validation)\n",
    "train_size = int(len(master_df) * 0.8)\n",
    "train_df = master_df.iloc[:train_size]\n",
    "val_df = master_df.iloc[train_size:]\n",
    "\n",
    "# ✅ Remove fully empty sequences\n",
    "train_df = train_df.dropna(how=\"all\")\n",
    "val_df = val_df.dropna(how=\"all\")\n",
    "\n",
    "# 📌 3. FILTERING SEQUENCES\n",
    "print(\"\\n🔹 Filtering sequences shorter than required length...\")\n",
    "train_df = train_df.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "val_df = val_df.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "print(f\"✅ After filtering: {len(train_df)} training rows, {len(val_df)} validation rows\")\n",
    "\n",
    "# 📌 4. CHECKING UNIQUE TIMESTAMP COUNTS\n",
    "print(\"\\n🔹 Checking unique sequence lengths per vehicle...\")\n",
    "print(train_df.groupby(\"vehicle\")[\"timestamp\"].nunique().describe())\n",
    "print(val_df.groupby(\"vehicle\")[\"timestamp\"].nunique().describe())\n",
    "\n",
    "# 📌 5. DETECTING EMPTY COLUMNS\n",
    "print(\"\\n🔹 Checking for empty columns in train and validation sets...\")\n",
    "empty_columns_train = train_df.columns[train_df.isna().all()]\n",
    "empty_columns_val = val_df.columns[val_df.isna().all()]\n",
    "print(f\"❌ Empty columns in train set: {list(empty_columns_train)}\")\n",
    "print(f\"❌ Empty columns in validation set: {list(empty_columns_val)}\")\n",
    "\n",
    "# ✅ Removing completely empty columns\n",
    "if \"activity\" in train_df.columns:\n",
    "    print(\"🚀 Removing empty column 'activity' from train and validation sets.\")\n",
    "    train_df = train_df.drop(columns=[\"activity\"])\n",
    "    val_df = val_df.drop(columns=[\"activity\"])\n",
    "\n",
    "# 📌 6. VERIFYING KEY COLUMNS HAVE DATA\n",
    "print(\"\\n🔹 Checking if `time_varying_unknown_reals` columns contain data...\")\n",
    "for col in [\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"]:\n",
    "    print(f\"🔹 {col} - Missing values: {train_df[col].isna().sum()} / {len(train_df)}\")\n",
    "\n",
    "# 📌 7. VERIFYING EMPTY SEQUENCES\n",
    "print(\"\\n🔹 Checking for empty sequences before creating TimeSeriesDataSet...\")\n",
    "empty_sequences_train = train_df.groupby(\"vehicle\").filter(lambda x: len(x) == 0)\n",
    "empty_sequences_val = val_df.groupby(\"vehicle\").filter(lambda x: len(x) == 0)\n",
    "print(f\"❌ Empty sequences in training set: {len(empty_sequences_train)}\")\n",
    "print(f\"❌ Empty sequences in validation set: {len(empty_sequences_val)}\")\n",
    "\n",
    "# 📌 8. CREATING TIME SERIES DATASETS\n",
    "print(\"\\n🔹 Creating TimeSeriesDataSet for training & validation...\")\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},  # Handles missing categories\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet(\n",
    "    val_df,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},\n",
    ")\n",
    "\n",
    "# 📌 9. FINAL OUTPUT\n",
    "print(\"\\n✅ Final dataset sizes:\")\n",
    "print(f\"📊 Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"📊 Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Checking for empty features in train dataset...\n",
      "🔹 timestamp: Missing values = 0, Zero values = 0\n",
      "🔹 acc_x_dashboard_left: Missing values = 0, Zero values = 93\n",
      "🔹 acc_y_dashboard_left: Missing values = 0, Zero values = 21\n",
      "🔹 acc_z_dashboard_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_x_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_y_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_z_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_x_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_y_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_z_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_x_dashboard_left: Missing values = 0, Zero values = 1053\n",
      "🔹 gyro_y_dashboard_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_z_dashboard_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_x_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_y_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_z_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_x_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_y_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 gyro_z_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 mag_x_dashboard_left: Missing values = 0, Zero values = 1262\n",
      "🔹 mag_y_dashboard_left: Missing values = 0, Zero values = 1536\n",
      "🔹 mag_z_dashboard_left: Missing values = 0, Zero values = 5459\n",
      "🔹 mag_x_above_suspension_left: Missing values = 0, Zero values = 1247\n",
      "🔹 mag_y_above_suspension_left: Missing values = 0, Zero values = 418\n",
      "🔹 mag_z_above_suspension_left: Missing values = 0, Zero values = 613\n",
      "🔹 temp_dashboard_left: Missing values = 0, Zero values = 3\n",
      "🔹 temp_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 temp_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "🔹 acc_x_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_y_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_z_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_x_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_y_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_z_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_x_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_y_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 acc_z_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_x_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_y_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_z_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_x_above_suspension_right: Missing values = 0, Zero values = 694\n",
      "🔹 gyro_y_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_z_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_x_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_y_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 gyro_z_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 mag_x_dashboard_right: Missing values = 0, Zero values = 1569\n",
      "🔹 mag_y_dashboard_right: Missing values = 0, Zero values = 1709\n",
      "🔹 mag_z_dashboard_right: Missing values = 0, Zero values = 9063\n",
      "🔹 mag_x_above_suspension_right: Missing values = 0, Zero values = 322\n",
      "🔹 mag_y_above_suspension_right: Missing values = 0, Zero values = 768\n",
      "🔹 mag_z_above_suspension_right: Missing values = 0, Zero values = 380\n",
      "🔹 temp_dashboard_right: Missing values = 0, Zero values = 1\n",
      "🔹 temp_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 temp_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "🔹 elevation: Missing values = 859343, Zero values = 0\n",
      "🔹 speed_meters_per_second: Missing values = 0, Zero values = 0\n",
      "🔹 satellites: Missing values = 859343, Zero values = 0\n",
      "🔹 hdop: Missing values = 859345, Zero values = 0\n",
      "🔹 vdop: Missing values = 859349, Zero values = 0\n",
      "🔹 pdop: Missing values = 859349, Zero values = 0\n",
      "🔹 distance_meters: Missing values = 859343, Zero values = 0\n",
      "🔹 elapsed_time_seconds: Missing values = 859343, Zero values = 0\n",
      "🔹 paved_road: Missing values = 0, Zero values = 231253\n",
      "🔹 unpaved_road: Missing values = 0, Zero values = 633471\n",
      "🔹 dirt_road: Missing values = 0, Zero values = 633471\n",
      "🔹 cobblestone_road: Missing values = 0, Zero values = 594507\n",
      "🔹 asphalt_road: Missing values = 0, Zero values = 501469\n",
      "🔹 no_speed_bump: Missing values = 0, Zero values = 14628\n",
      "🔹 speed_bump_asphalt: Missing values = 0, Zero values = 858471\n",
      "🔹 speed_bump_cobblestone: Missing values = 0, Zero values = 856348\n",
      "🔹 good_road_left: Missing values = 0, Zero values = 507386\n",
      "🔹 regular_road_left: Missing values = 0, Zero values = 503230\n",
      "🔹 bad_road_left: Missing values = 0, Zero values = 718832\n",
      "🔹 good_road_right: Missing values = 0, Zero values = 507570\n",
      "🔹 regular_road_right: Missing values = 0, Zero values = 499146\n",
      "🔹 bad_road_right: Missing values = 0, Zero values = 722732\n",
      "🔹 experiment_id: Missing values = 0, Zero values = 0\n",
      "🔹 vehicle: Missing values = 0, Zero values = 0\n",
      "🔹 scenario: Missing values = 0, Zero values = 0\n",
      "\n",
      "✅ Checking unique sequence lengths in train dataset (filtered):\n",
      "count       3.000000\n",
      "mean     2884.000000\n",
      "std      1393.818137\n",
      "min      1276.000000\n",
      "25%      2452.500000\n",
      "50%      3629.000000\n",
      "75%      3688.000000\n",
      "max      3747.000000\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "✅ Checking unique sequence lengths in validation dataset (filtered):\n",
      "count       1.0\n",
      "mean     2164.0\n",
      "std         NaN\n",
      "min      2164.0\n",
      "25%      2164.0\n",
      "50%      2164.0\n",
      "75%      2164.0\n",
      "max      2164.0\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "✅ Train DataLoader batches: 6654\n",
      "✅ Validation DataLoader batches: 1652\n",
      "\n",
      "✅ Checking first batch from DataLoader...\n",
      "❌ Error fetching batch: stack expects each tensor to be equal size, but got [1808, 0] at entry 0 and [1892, 0] at entry 1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ✅ Step 0: Check for empty features in train_df before DataLoader\n",
    "print(\"\\n🔹 Checking for empty features in train dataset...\")\n",
    "for key in train_df.columns:\n",
    "    num_missing = train_df[key].isna().sum()\n",
    "    num_zeros = (train_df[key] == 0).sum()\n",
    "    print(f\"🔹 {key}: Missing values = {num_missing}, Zero values = {num_zeros}\")\n",
    "\n",
    "# ✅ Step 1: Check unique sequence lengths\n",
    "print(\"\\n✅ Checking unique sequence lengths in train dataset (filtered):\")\n",
    "train_sequence_lengths = train_df.groupby(\"vehicle\")[\"timestamp\"].nunique()\n",
    "print(train_sequence_lengths.describe())  \n",
    "\n",
    "print(\"\\n✅ Checking unique sequence lengths in validation dataset (filtered):\")\n",
    "val_sequence_lengths = val_df.groupby(\"vehicle\")[\"timestamp\"].nunique()\n",
    "print(val_sequence_lengths.describe())\n",
    "\n",
    "# ✅ Step 2: Define batch size\n",
    "batch_size = 128\n",
    "\n",
    "# ✅ Step 3: Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\n✅ Train DataLoader batches: {len(train_dataloader)}\")\n",
    "print(f\"✅ Validation DataLoader batches: {len(val_dataloader)}\")\n",
    "\n",
    "# ✅ Step 4: Debug DataLoader fetching\n",
    "print(\"\\n✅ Checking first batch from DataLoader...\")\n",
    "\n",
    "try:\n",
    "    first_batch = next(iter(train_dataloader))\n",
    "    print(\"✅ Successfully fetched a batch\")\n",
    "    print(\"🔹 Batch Keys:\", first_batch.keys())\n",
    "\n",
    "    for key, value in first_batch.items():\n",
    "        print(f\"   🔹 {key}: Shape = {value.shape if isinstance(value, torch.Tensor) else type(value)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error fetching batch:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Starting Aggressive Data Cleaning Process...\n",
      "🚀 Dropping high-missing-value columns: ['elevation', 'satellites', 'hdop', 'vdop', 'pdop', 'distance_meters', 'elapsed_time_seconds']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  val_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  val_df_cleaned.fillna(method=\"bfill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Verifying sequence lengths after aggressive cleaning...\n",
      "✅ After cleaning: 864724 training rows, 216181 validation rows\n",
      "\n",
      "🔹 Creating new TimeSeriesDataSet with aggressively cleaned data...\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: group_ids (1449649126.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[69], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    group_ids=[\"vehicle\"],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: group_ids\n"
     ]
    }
   ],
   "source": [
    "# 📌 CELL 3: Aggressive Data Cleaning & Preparing Data for TFT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n🔹 Starting Aggressive Data Cleaning Process...\")\n",
    "\n",
    "# ✅ Step 1: Identify columns to drop (ONLY if completely useless)\n",
    "high_missing_cols = [\"elevation\", \"satellites\", \"hdop\", \"vdop\", \"pdop\", \n",
    "                     \"distance_meters\", \"elapsed_time_seconds\"]\n",
    "\n",
    "print(f\"🚀 Dropping high-missing-value columns: {high_missing_cols}\")\n",
    "\n",
    "train_df_cleaned = train_df.drop(columns=high_missing_cols, errors=\"ignore\")\n",
    "val_df_cleaned = val_df.drop(columns=high_missing_cols, errors=\"ignore\")\n",
    "\n",
    "# ✅ Step 2: Fill remaining missing values intelligently\n",
    "# Forward-fill first, then back-fill as a safety net\n",
    "train_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
    "train_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "val_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
    "val_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "# **NEW**: Fill any remaining NaNs with the median value of each column\n",
    "for col in train_df_cleaned.columns:\n",
    "    if train_df_cleaned[col].isna().sum() > 0:\n",
    "        median_value = train_df_cleaned[col].median()\n",
    "        train_df_cleaned[col].fillna(median_value, inplace=True)\n",
    "\n",
    "for col in val_df_cleaned.columns:\n",
    "    if val_df_cleaned[col].isna().sum() > 0:\n",
    "        median_value = val_df_cleaned[col].median()\n",
    "        val_df_cleaned[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# ✅ Step 3: Replace zero values in key features to prevent model breakage\n",
    "zero_replacement_cols = [\"speed_meters_per_second\", \"acc_x_dashboard_left\", \"acc_y_dashboard_left\"]\n",
    "for col in zero_replacement_cols:\n",
    "    train_df_cleaned[col] = train_df_cleaned[col].replace(0, train_df_cleaned[col].median())\n",
    "    val_df_cleaned[col] = val_df_cleaned[col].replace(0, val_df_cleaned[col].median())\n",
    "\n",
    "# ✅ Step 4: Ensure sequences are still valid\n",
    "print(\"\\n🔹 Verifying sequence lengths after aggressive cleaning...\")\n",
    "\n",
    "train_df_cleaned = train_df_cleaned.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "val_df_cleaned = val_df_cleaned.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "\n",
    "print(f\"✅ After cleaning: {len(train_df_cleaned)} training rows, {len(val_df_cleaned)} validation rows\")\n",
    "\n",
    "# ✅ Step 5: Re-create TimeSeriesDataSet with cleaned data\n",
    "print(\"\\n🔹 Creating new TimeSeriesDataSet with aggressively cleaned data...\")\n",
    "\n",
    "train_dataset_cleaned = TimeSeriesDataSet(\n",
    "    train_df_cleaned,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    static_categoricals=[\"vehicle\"],  # ✅ Add this line to define `vehicle` as a categorical feature\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    group_ids=[\"vehicle\"],\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},  # Handles missing categories\n",
    ")\n",
    "\n",
    "val_dataset_cleaned = TimeSeriesDataSet(\n",
    "    val_df_cleaned,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    static_categoricals=[\"vehicle\"],  # ✅ Add this line here too\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    group_ids=[\"vehicle\"],\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},\n",
    ")\n",
    "\n",
    "# ✅ Step 6: Final Dataset Validation\n",
    "print(\"\\n✅ Final cleaned dataset sizes:\")\n",
    "print(f\"📊 Train dataset size: {len(train_dataset_cleaned)}\")\n",
    "print(f\"📊 Validation dataset size: {len(val_dataset_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Extracting a SMALL dataset sample for debugging...\n",
      "\n",
      "🔍 Checking column lengths in Train dataset (Debug Sample)...\n",
      "🔹 Column: reals, Shape: torch.Size([864724, 6])\n",
      "🔹 Column: categoricals, Shape: torch.Size([864724, 1])\n",
      "🔹 Column: groups, Shape: torch.Size([864724, 1])\n",
      "🔹 Column: target, Shape: 1\n",
      "❌ Warning: Column weight is None!\n",
      "🔹 Column: time, Shape: torch.Size([864724])\n",
      "\n",
      "🔍 Checking column lengths in Validation dataset (Debug Sample)...\n",
      "🔹 Column: reals, Shape: torch.Size([216181, 6])\n",
      "🔹 Column: categoricals, Shape: torch.Size([216181, 1])\n",
      "🔹 Column: groups, Shape: torch.Size([216181, 1])\n",
      "🔹 Column: target, Shape: 1\n",
      "❌ Warning: Column weight is None!\n",
      "🔹 Column: time, Shape: torch.Size([216181])\n",
      "🔍 BEFORE FIX: `train.categoricals` shape = torch.Size([864724, 1])\n",
      "🔍 BEFORE FIX: `val.categoricals` shape = torch.Size([216181, 1])\n",
      "✅ AFTER FIX: `train.categoricals` shape = torch.Size([864724, 1])\n",
      "✅ AFTER FIX: `val.categoricals` shape = torch.Size([216181, 1])\n",
      "\n",
      "🔍 Final dataset keys before DataLoader creation:\n",
      "🔹 Train dataset keys: ['reals', 'categoricals', 'groups', 'target', 'weight', 'time']\n",
      "🔹 Validation dataset keys: ['reals', 'categoricals', 'groups', 'target', 'weight', 'time']\n",
      "\n",
      "🔍 Checking for empty or incorrect columns before DataFrame creation...\n",
      "🔄 Fixing `target` in train dataset: Extracting tensor...\n",
      "🔄 Converting `target` tensor to NumPy array in train dataset...\n",
      "🔄 Fixing `target` in val dataset: Extracting tensor...\n",
      "🔄 Converting `target` tensor to NumPy array in val dataset...\n",
      "\n",
      "✅ `target` column successfully fixed for both datasets!\n",
      "\n",
      "🔍 Checking dataset length consistency before trimming...\n",
      "\n",
      "🔹 Train dataset keys: ['reals', 'categoricals', 'groups', 'target', 'time']\n",
      "🔹 Validation dataset keys: ['reals', 'categoricals', 'groups', 'target', 'time']\n",
      "\n",
      "🔍 Train dataset column lengths:\n",
      "   - `reals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `categoricals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `groups`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `target`: Length = 864724 | Shape = (864724,)\n",
      "   - `time`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "\n",
      "🔍 Validation dataset column lengths:\n",
      "   - `reals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `categoricals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `groups`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `target`: Length = 216181 | Shape = (216181,)\n",
      "   - `time`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "\n",
      "🔍 Inspecting first 5 records for each feature in TRAIN dataset:\n",
      "\n",
      "🔹 Feature: `reals`\n",
      "[[-1.1649995  -1.166046    0.37036544  0.          0.2901575   0.17322966]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.04296927  0.4961055 ]\n",
      " [-1.1649995  -1.166046    0.37036544  0.         -0.04819235  0.33333337]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.21652696 -0.04157615]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.25158912  0.2065846 ]]\n",
      "\n",
      "🔹 Feature: `categoricals`\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "🔹 Feature: `groups`\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "🔹 Feature: `target`\n",
      "[22.576147 22.576147 22.576147 22.576147 22.576147]\n",
      "\n",
      "🔹 Feature: `time`\n",
      "[1577306803 1577306803 1577306803 1577306803 1577306803]\n",
      "\n",
      "✅ Final `categoricals` Shape in Train Dataset: torch.Size([864724, 1])\n",
      "\n",
      "🔍 Inspecting first 5 records for each feature in VALIDATION dataset:\n",
      "\n",
      "🔹 Feature: `reals`\n",
      "[[ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.2830735e-01 -2.4845469e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.2072284e-01 -2.2991690e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -8.9322901e-01 -2.3918580e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -8.9417708e-01 -2.3238860e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.3778795e-01 -2.5710565e-01]]\n",
      "\n",
      "🔹 Feature: `categoricals`\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "🔹 Feature: `groups`\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "🔹 Feature: `target`\n",
      "[0.7602653 0.7602653 0.7602653 0.7602653 0.7602653]\n",
      "\n",
      "🔹 Feature: `time`\n",
      "[1577396705 1577396705 1577396705 1577396705 1577396705]\n",
      "\n",
      "✅ Feature inspection completed.\n",
      "✅ DataFrame created successfully!\n",
      "\n",
      "🔹 Train dataset sample:\n",
      "           target        time\n",
      "659348   2.115313  1577221418\n",
      "367583   0.013329  1577395479\n",
      "729957   9.086297  1577222124\n",
      "56398    6.685661  1577307367\n",
      "135961   5.780402  1577308639\n",
      "275275   0.022758  1577310339\n",
      "816169  22.576147  1577223941\n",
      "784166  22.576147  1577223621\n",
      "371017  16.763273  1577395514\n",
      "288893   0.022758  1577310476\n",
      "\n",
      "🔹 Validation dataset sample:\n",
      "           target        time\n",
      "183849   2.914004  1577399597\n",
      "131084  21.062319  1577399069\n",
      "162666   8.601702  1577399385\n",
      "200025  19.179893  1577399759\n",
      "24914    0.044819  1577397296\n",
      "166927   7.926495  1577399428\n",
      "205860  21.770510  1577399817\n",
      "20670    0.044819  1577397254\n",
      "133662  22.811634  1577399095\n",
      "60870    0.044819  1577397656\n",
      "\n",
      "🔹 Checking for missing values in Train dataset...\n",
      "target    0\n",
      "time      0\n",
      "dtype: int64\n",
      "\n",
      "🔹 Checking for missing values in Validation dataset...\n",
      "target    0\n",
      "time      0\n",
      "dtype: int64\n",
      "\n",
      "✅ Data extraction and alignment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 📌 CELL 4: Debugging Before DataLoader Creation\n",
    "\n",
    "print(\"\\n🔹 Extracting a SMALL dataset sample for debugging...\")\n",
    "\n",
    "# ✅ Set Debugging Sample Size (e.g., 50,000 for performance)\n",
    "DEBUG_SAMPLE_SIZE = 100_000\n",
    "\n",
    "# ✅ Extract a smaller dataset sample instead of full dataset\n",
    "train_data_dict = train_dataset_cleaned.to_dataloader(batch_size=DEBUG_SAMPLE_SIZE).dataset.data\n",
    "val_data_dict = val_dataset_cleaned.to_dataloader(batch_size=DEBUG_SAMPLE_SIZE).dataset.data\n",
    "\n",
    "# ✅ Debug: Check structure of extracted dictionary\n",
    "print(\"\\n🔍 Checking column lengths in Train dataset (Debug Sample)...\")\n",
    "for key, value in train_data_dict.items():\n",
    "    if value is None:\n",
    "        print(f\"❌ Warning: Column {key} is None!\")\n",
    "    else:\n",
    "        print(f\"🔹 Column: {key}, Shape: {value.shape if hasattr(value, 'shape') else len(value)}\")\n",
    "\n",
    "print(\"\\n🔍 Checking column lengths in Validation dataset (Debug Sample)...\")\n",
    "for key, value in val_data_dict.items():\n",
    "    if value is None:\n",
    "        print(f\"❌ Warning: Column {key} is None!\")\n",
    "    else:\n",
    "        print(f\"🔹 Column: {key}, Shape: {value.shape if hasattr(value, 'shape') else len(value)}\")\n",
    "\n",
    "# ✅ Step 1: Drop Unnecessary Columns (`reals`, `groups`, `categoricals`)\n",
    "# columns_to_drop = [\"reals\", \"groups\", \"categoricals\"]\n",
    "\n",
    "# for col in columns_to_drop:\n",
    "#     if col in train_data_dict:\n",
    "#         print(f\"🗑️ Dropping `{col}` from Train dataset...\")\n",
    "#         del train_data_dict[col]\n",
    "#     if col in val_data_dict:\n",
    "#         print(f\"🗑️ Dropping `{col}` from Validation dataset...\")\n",
    "#         del val_data_dict[col]\n",
    "\n",
    "# print(\"\\n✅ `reals`, `groups`, and `categoricals` successfully removed from both datasets!\")\n",
    "\n",
    "# ✅ Print Before Fixing `categoricals`\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"categoricals\" in dataset_dict:\n",
    "        print(f\"🔍 BEFORE FIX: `{dataset_name}.categoricals` shape = {dataset_dict['categoricals'].shape}\")\n",
    "\n",
    "# ✅ Ensure `categoricals` is 2D and has at least one column\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"categoricals\" in dataset_dict:\n",
    "        if dataset_dict[\"categoricals\"].size == 0:  # If it's an empty (N,0) tensor\n",
    "            dataset_dict[\"categoricals\"] = torch.zeros((len(dataset_dict[\"target\"]), 1))  # Add one column of zeros\n",
    "        \n",
    "        print(f\"✅ AFTER FIX: `{dataset_name}.categoricals` shape = {dataset_dict['categoricals'].shape}\")\n",
    "\n",
    "\n",
    "# ✅ Final check: Ensure `reals` is removed before creating DataLoaders\n",
    "print(\"\\n🔍 Final dataset keys before DataLoader creation:\")\n",
    "print(\"🔹 Train dataset keys:\", list(train_data_dict.keys()))\n",
    "print(\"🔹 Validation dataset keys:\", list(val_data_dict.keys()))\n",
    "\n",
    "\n",
    "# ✅ Remove NoneType values before checking length\n",
    "train_data_dict = {k: v for k, v in train_data_dict.items() if v is not None}\n",
    "val_data_dict = {k: v for k, v in val_data_dict.items() if v is not None}\n",
    "\n",
    "# 🚨 **Step 2: Detect & Remove Empty Columns**\n",
    "print(\"\\n🔍 Checking for empty or incorrect columns before DataFrame creation...\")\n",
    "columns_to_remove = []\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    for key, value in dataset_dict.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"   🔹 `{dataset_name}.{key}`: Shape = {value.shape}\")\n",
    "\n",
    "            # 🚨 Remove empty or malformed columns\n",
    "            if value.size == 0 or value.shape in [(), (1, 0)]:\n",
    "                print(f\"🚨 WARNING: `{key}` in {dataset_name} is EMPTY or malformed! Removing column.\")\n",
    "                columns_to_remove.append((dataset_name, key))\n",
    "\n",
    "# 🚨 **Remove Problematic Columns**\n",
    "for dataset_name, key in columns_to_remove:\n",
    "    if dataset_name == \"train\":\n",
    "        del train_data_dict[key]\n",
    "    else:\n",
    "        del val_data_dict[key]\n",
    "\n",
    "# ✅ Step 3: Fix `target` Column (Flatten & Convert)\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"target\" in dataset_dict:\n",
    "        if isinstance(dataset_dict[\"target\"], list) and len(dataset_dict[\"target\"]) == 1:\n",
    "            print(f\"🔄 Fixing `target` in {dataset_name} dataset: Extracting tensor...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"][0]  # Extract tensor\n",
    "        \n",
    "        if isinstance(dataset_dict[\"target\"], torch.Tensor):\n",
    "            print(f\"🔄 Converting `target` tensor to NumPy array in {dataset_name} dataset...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"].cpu().numpy()  # Convert to NumPy\n",
    "        \n",
    "        if dataset_dict[\"target\"].ndim > 1:\n",
    "            print(f\"⚠️ `target` in {dataset_name} is multi-dimensional ({dataset_dict['target'].shape}), flattening...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"].reshape(-1)  # Flatten to 1D\n",
    "\n",
    "print(\"\\n✅ `target` column successfully fixed for both datasets!\")\n",
    "\n",
    "# # 🚨 **Step 3: Fix `groups` & `time` Columns**\n",
    "# for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "#     for key in dataset_dict.keys():\n",
    "#         if isinstance(dataset_dict[key], np.ndarray):\n",
    "#             # 🚨 Fix `groups` column\n",
    "#             if key == \"groups\":\n",
    "#                 if dataset_dict[key].ndim == 0 or dataset_dict[key].shape == ():\n",
    "#                     print(f\"⚠️ WARNING: `{key}` in {dataset_name} is scalar! Converting to 1D array...\")\n",
    "#                     dataset_dict[key] = np.array([dataset_dict[key]])  # Convert to array\n",
    "\n",
    "#             # 🚨 Fix `time` column\n",
    "#             if key == \"time\":\n",
    "#                 if dataset_dict[key].ndim != 1:\n",
    "#                     print(f\"⚠️ WARNING: `{key}` in {dataset_name} is not 1D! Flattening...\")\n",
    "#                     dataset_dict[key] = dataset_dict[key].reshape(-1)  # Force 1D shape\n",
    "            \n",
    "#             # 🚨 Catch remaining multi-dimensional issues\n",
    "#             if dataset_dict[key].ndim > 1:\n",
    "#                 print(f\"⚠️ Column `{key}` in {dataset_name} is multi-dimensional ({dataset_dict[key].shape}), flattening...\")\n",
    "#                 dataset_dict[key] = dataset_dict[key].reshape(-1)  # Flatten to 1D\n",
    "\n",
    "# ✅ **Step 4: Trim Dataset Lengths for Consistency**\n",
    "print(\"\\n🔍 Checking dataset length consistency before trimming...\")\n",
    "\n",
    "# 🚀 Print dataset keys\n",
    "print(\"\\n🔹 Train dataset keys:\", list(train_data_dict.keys()))\n",
    "print(\"🔹 Validation dataset keys:\", list(val_data_dict.keys()))\n",
    "\n",
    "# 🚀 Print each column's length before calculating min length\n",
    "print(\"\\n🔍 Train dataset column lengths:\")\n",
    "for key, value in train_data_dict.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"   - `{key}`: Length = {len(value)} | Shape = {value.shape}\")\n",
    "    else:\n",
    "        print(f\"   - `{key}`: Type = {type(value)} (Not an ndarray)\")\n",
    "\n",
    "print(\"\\n🔍 Validation dataset column lengths:\")\n",
    "for key, value in val_data_dict.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"   - `{key}`: Length = {len(value)} | Shape = {value.shape}\")\n",
    "    else:\n",
    "        print(f\"   - `{key}`: Type = {type(value)} (Not an ndarray)\")\n",
    "\n",
    "\n",
    "# 🚀 **Step 4.1: Print First 5 Records for Each Column**\n",
    "print(\"\\n🔍 Inspecting first 5 records for each feature in TRAIN dataset:\")\n",
    "\n",
    "for key, value in train_data_dict.items():\n",
    "    try:\n",
    "        print(f\"\\n🔹 Feature: `{key}`\")\n",
    "        \n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(value[:5].cpu().numpy())  # Convert tensor to NumPy and print first 5 records\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(value[:5])  # Directly print first 5 records\n",
    "        elif isinstance(value, list):\n",
    "            print(value[:5])  # Print first 5 records if it's a list\n",
    "        else:\n",
    "            print(f\"❌ Unexpected data type: {type(value)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing `{key}`:\", e)\n",
    "\n",
    "print(\"\\n✅ Final `categoricals` Shape in Train Dataset:\", train_data_dict[\"categoricals\"].shape)\n",
    "\n",
    "# Step 4.2: Repeat for Validation Dataset\n",
    "print(\"\\n🔍 Inspecting first 5 records for each feature in VALIDATION dataset:\")\n",
    "\n",
    "for key, value in val_data_dict.items():\n",
    "    try:\n",
    "        print(f\"\\n🔹 Feature: `{key}`\")\n",
    "        \n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(value[:5].cpu().numpy())  # Convert tensor to NumPy and print first 5 records\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(value[:5])  # Directly print first 5 records\n",
    "        elif isinstance(value, list):\n",
    "            print(value[:5])  # Print first 5 records if it's a list\n",
    "        else:\n",
    "            print(f\"❌ Unexpected data type: {type(value)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing `{key}`:\", e)\n",
    "\n",
    "print(\"\\n✅ Feature inspection completed.\")\n",
    "\n",
    "\n",
    "# ✅ Temporarily remove `categoricals` and `groups` before DataFrame conversion \n",
    "# (since Pandas doesn't support 2D arrays)\n",
    "train_data_dict_for_df = {\n",
    "    k: v.cpu().numpy() if isinstance(v, torch.Tensor) else v \n",
    "    for k, v in train_data_dict.items() if k not in [\"reals\", \"categoricals\", \"groups\"]\n",
    "}\n",
    "val_data_dict_for_df = {\n",
    "    k: v.cpu().numpy() if isinstance(v, torch.Tensor) else v \n",
    "    for k, v in val_data_dict.items() if k not in [\"reals\", \"categoricals\", \"groups\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    train_df_debug = pd.DataFrame.from_dict(train_data_dict_for_df).sample(10)\n",
    "    val_df_debug = pd.DataFrame.from_dict(val_data_dict_for_df).sample(10)\n",
    "    print(\"✅ DataFrame created successfully!\")\n",
    "except ValueError as e:\n",
    "    print(\"\\n❌ ERROR: Could not create Pandas DataFrame! The dataset is likely empty.\", e)\n",
    "    raise e\n",
    "\n",
    "# ✅ **Step 6: Print Final Debugging Info**\n",
    "print(\"\\n🔹 Train dataset sample:\")\n",
    "print(train_df_debug)\n",
    "\n",
    "print(\"\\n🔹 Validation dataset sample:\")\n",
    "print(val_df_debug)\n",
    "\n",
    "# ✅ **Check for missing values**\n",
    "print(\"\\n🔹 Checking for missing values in Train dataset...\")\n",
    "print(train_df_debug.isna().sum())\n",
    "\n",
    "print(\"\\n🔹 Checking for missing values in Validation dataset...\")\n",
    "print(val_df_debug.isna().sum())\n",
    "\n",
    "print(\"\\n✅ Data extraction and alignment completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Initializing TemporalFusionTransformer model with cleaned data...\n",
      "\n",
      "✅ TemporalFusionTransformer Model Initialized Successfully!\n",
      "TemporalFusionTransformer(\n",
      "  \t\"attention_head_size\":               4\n",
      "  \t\"categorical_groups\":                {}\n",
      "  \t\"causal_attention\":                  True\n",
      "  \t\"dataset_parameters\":                {'time_idx': 'timestamp', 'target': 'speed_meters_per_second', 'group_ids': ['vehicle'], 'weight': None, 'max_encoder_length': 15, 'min_encoder_length': 15, 'min_prediction_idx': 1577218796, 'min_prediction_length': 5, 'max_prediction_length': 5, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': ['timestamp'], 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['acc_x_dashboard_left', 'acc_y_dashboard_left'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': True, 'lags': None, 'add_relative_time_idx': True, 'add_target_scales': True, 'add_encoder_length': False, 'target_normalizer': GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['vehicle'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t), 'categorical_encoders': {'vehicle': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__vehicle': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'speed_meters_per_second_center': StandardScaler(), 'speed_meters_per_second_scale': StandardScaler(), 'timestamp': StandardScaler(), 'relative_time_idx': StandardScaler(), 'acc_x_dashboard_left': StandardScaler(), 'acc_y_dashboard_left': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
      "  \t\"dropout\":                           0.1\n",
      "  \t\"embedding_labels\":                  {}\n",
      "  \t\"embedding_paddings\":                ['vehicle']\n",
      "  \t\"embedding_sizes\":                   {}\n",
      "  \t\"hidden_continuous_size\":            16\n",
      "  \t\"hidden_continuous_sizes\":           {}\n",
      "  \t\"hidden_size\":                       64\n",
      "  \t\"learning_rate\":                     0.001\n",
      "  \t\"log_gradient_flow\":                 False\n",
      "  \t\"log_interval\":                      10\n",
      "  \t\"log_val_interval\":                  10\n",
      "  \t\"lstm_layers\":                       1\n",
      "  \t\"max_encoder_length\":                15\n",
      "  \t\"monotone_constaints\":               {}\n",
      "  \t\"monotone_constraints\":              {}\n",
      "  \t\"optimizer\":                         adam\n",
      "  \t\"optimizer_params\":                  None\n",
      "  \t\"output_size\":                       1\n",
      "  \t\"output_transformer\":                GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['vehicle'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t)\n",
      "  \t\"reduce_on_plateau_min_lr\":          1e-05\n",
      "  \t\"reduce_on_plateau_patience\":        4\n",
      "  \t\"reduce_on_plateau_reduction\":       2.0\n",
      "  \t\"share_single_variable_networks\":    False\n",
      "  \t\"static_categoricals\":               []\n",
      "  \t\"static_reals\":                      ['speed_meters_per_second_center', 'speed_meters_per_second_scale']\n",
      "  \t\"time_varying_categoricals_decoder\": []\n",
      "  \t\"time_varying_categoricals_encoder\": []\n",
      "  \t\"time_varying_reals_decoder\":        ['timestamp', 'relative_time_idx']\n",
      "  \t\"time_varying_reals_encoder\":        ['timestamp', 'relative_time_idx', 'acc_x_dashboard_left', 'acc_y_dashboard_left']\n",
      "  \t\"weight_decay\":                      0.0\n",
      "  \t\"x_categoricals\":                    []\n",
      "  \t\"x_reals\":                           ['speed_meters_per_second_center', 'speed_meters_per_second_scale', 'timestamp', 'relative_time_idx', 'acc_x_dashboard_left', 'acc_y_dashboard_left']\n",
      "  (loss): QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
      "  (logging_metrics): ModuleList(\n",
      "    (0): SMAPE()\n",
      "    (1): MAE()\n",
      "    (2): RMSE()\n",
      "    (3): MAPE()\n",
      "  )\n",
      "  (input_embeddings): MultiEmbedding(\n",
      "    (embeddings): ModuleDict()\n",
      "  )\n",
      "  (prescalers): ModuleDict(\n",
      "    (speed_meters_per_second_center): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (speed_meters_per_second_scale): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (acc_x_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (acc_y_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "  )\n",
      "  (static_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (speed_meters_per_second_center): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (speed_meters_per_second_scale): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (speed_meters_per_second_center): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (speed_meters_per_second_scale): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (encoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=4, out_features=8, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (timestamp): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (relative_time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (acc_x_dashboard_left): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (acc_y_dashboard_left): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (acc_x_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (acc_y_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (decoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=64, out_features=2, bias=False)\n",
      "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (timestamp): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (relative_time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (static_context_variable_selection): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm_encoder): LSTM(64, 64, batch_first=True)\n",
      "  (lstm_decoder): LSTM(64, 64, batch_first=True)\n",
      "  (post_lstm_gate_encoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (post_lstm_gate_decoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_encoder): AddNorm(\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_decoder): AddNorm(\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (static_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (context): Linear(in_features=64, out_features=64, bias=False)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (multihead_attn): InterpretableMultiHeadAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (v_layer): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (q_layers): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "    (k_layers): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "    (attention): ScaledDotProductAttention(\n",
      "      (softmax): Softmax(dim=2)\n",
      "    )\n",
      "    (w_h): Linear(in_features=16, out_features=64, bias=False)\n",
      "  )\n",
      "  (post_attn_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pos_wise_ff): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_output_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# 🚀 Step 1: Define TFT model using the cleaned training dataset\n",
    "print(\"\\n🔹 Initializing TemporalFusionTransformer model with cleaned data...\")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset_cleaned,  # ✅ Now using the CLEANED training dataset\n",
    "    learning_rate=0.001,  # Initial learning rate\n",
    "    hidden_size=64,  # LSTM hidden units\n",
    "    attention_head_size=4,  # Attention heads\n",
    "    dropout=0.1,  # Dropout for regularization\n",
    "    hidden_continuous_size=16,  # Hidden layer for continuous variables\n",
    "    loss=QuantileLoss(),  # ✅ Using Quantile Loss\n",
    "    log_interval=10,  # Log progress every 10 steps\n",
    "    output_size=1,  # Single target variable (speed_meters_per_second)\n",
    "    reduce_on_plateau_patience=4  # Reduce LR if no improvement after 4 epochs\n",
    ")\n",
    "\n",
    "# 🚀 Step 2: Print model summary\n",
    "print(\"\\n✅ TemporalFusionTransformer Model Initialized Successfully!\")\n",
    "print(tft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Starting Trainer Initialization...\n",
      "✅ Trainer initialized successfully.\n",
      "✅ Initializing TemporalFusionTransformer model...\n",
      "🔹 Encoder Reals: ['target']\n",
      "🔹 Decoder Reals: ['time']\n",
      "✅ TFT model initialized.\n",
      "✅ Wrapping model in TFTLightningModule...\n",
      "✅ Model wrapped.\n",
      "\n",
      "🔹 Checking first batch from cleaned DataLoader before training...\n",
      "\n",
      "🔍 Checking `train_dataset_cleaned` feature configuration...\n",
      "✅ Successfully retrieved dataset parameters!\n",
      "   - Static Categoricals: ['vehicle']\n",
      "   - Time-Varying Reals Encoder: []\n",
      "   - Time-Varying Reals Decoder: []\n",
      "   - Target: speed_meters_per_second\n",
      "✅ Cleaned DataLoaders created successfully!\n",
      "\n",
      "🔍 Checking if train_dataloader_cleaned is properly initialized...\n",
      "   - DataLoader Length: 13306\n",
      "   - DataLoader dataset type: <class 'pytorch_forecasting.data.timeseries.TimeSeriesDataSet'>\n",
      "   - Dataset Length: 851585\n",
      "\n",
      "🔍 Checking `train_dataset_cleaned` BEFORE DataLoader creation...\n",
      "❌ Error fetching first records from train_dataset_cleaned: slice indices must be integers or None or have an __index__ method\n",
      "\n",
      "🚀 Attempting to fetch first batch...\n",
      "✅ Successfully fetched batch 1\n",
      "❌ Error fetching batch: 'tuple' object has no attribute 'keys'\n",
      "\n",
      "🚀 Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ✅ Step 1: Define the LightningModule wrapper for TFT\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model  # Assign the TFT model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_pred, _ = self.model(batch)  \n",
    "        loss = self.model.loss(y_pred, batch[\"encoder_target\"])  \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_pred, _ = self.model(batch)\n",
    "        loss = self.model.loss(y_pred, batch[\"encoder_target\"])  \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "print(\"✅ Starting Trainer Initialization...\")\n",
    "\n",
    "# ✅ Step 2: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")]\n",
    ")\n",
    "\n",
    "print(\"✅ Trainer initialized successfully.\")\n",
    "\n",
    "# ✅ Step 3: Define TFT Model (Fixing `reals` issue)\n",
    "print(\"✅ Initializing TemporalFusionTransformer model...\")\n",
    "\n",
    "# 🚀 Extract column names from dataset dictionary\n",
    "try:\n",
    "    dataset_columns = list(train_dataset_cleaned.data.keys())  # ✅ Get dictionary keys\n",
    "except Exception as e:\n",
    "    print(\"❌ ERROR: Could not retrieve column names from dataset:\", e)\n",
    "    dataset_columns = []\n",
    "\n",
    "# 🚀 Define encoder/decoder variables (excluding `reals`)\n",
    "time_varying_reals_encoder = [\"target\"] if \"target\" in dataset_columns else []\n",
    "time_varying_reals_decoder = [\"time\"] if \"time\" in dataset_columns else []\n",
    "\n",
    "print(f\"🔹 Encoder Reals: {time_varying_reals_encoder}\")\n",
    "print(f\"🔹 Decoder Reals: {time_varying_reals_decoder}\")\n",
    "\n",
    "# ✅ Create TemporalFusionTransformer model\n",
    "try:\n",
    "    tft_model = TemporalFusionTransformer.from_dataset(\n",
    "        train_dataset_cleaned,  # ✅ Using the CLEANED dataset\n",
    "        learning_rate=0.001,\n",
    "        hidden_size=64,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.1,\n",
    "        loss=QuantileLoss(),\n",
    "        output_size=1,  \n",
    "        log_interval=10,\n",
    "        reduce_on_plateau_patience=4,\n",
    "        static_categoricals=[],  # ✅ Ensure empty if no static categorical features\n",
    "        time_varying_reals_encoder=time_varying_reals_encoder,  # ✅ Corrected\n",
    "        time_varying_reals_decoder=time_varying_reals_decoder,  # ✅ Corrected\n",
    "    )\n",
    "    print(\"✅ TFT model initialized.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ ERROR: TFT Model Initialization Failed:\", e)\n",
    "    raise e\n",
    "\n",
    "# ✅ Step 4: Wrap TFT in the LightningModule\n",
    "print(\"✅ Wrapping model in TFTLightningModule...\")\n",
    "tft_lightning = TFTLightningModule(tft_model)\n",
    "print(\"✅ Model wrapped.\")\n",
    "\n",
    "# ✅ Step 5: Debug First Batch Before Training\n",
    "print(\"\\n🔹 Checking first batch from cleaned DataLoader before training...\")\n",
    "\n",
    "# ✅ Define batch size\n",
    "BATCH_SIZE = 64  # Adjust based on memory constraints\n",
    "\n",
    "# 🚀 Checking the dataset feature configuration\n",
    "print(\"\\n🔍 Checking `train_dataset_cleaned` feature configuration...\")\n",
    "\n",
    "try:\n",
    "    dataset_features = train_dataset_cleaned.get_parameters()  # ✅ Fetch dataset parameters\n",
    "    print(\"✅ Successfully retrieved dataset parameters!\")\n",
    "\n",
    "    # Print key settings to check if \"reals\" still exists\n",
    "    print(f\"   - Static Categoricals: {dataset_features.get('static_categoricals', [])}\")\n",
    "    print(f\"   - Time-Varying Reals Encoder: {dataset_features.get('time_varying_reals_encoder', [])}\")\n",
    "    print(f\"   - Time-Varying Reals Decoder: {dataset_features.get('time_varying_reals_decoder', [])}\")\n",
    "    print(f\"   - Target: {dataset_features.get('target', 'Not Specified')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error retrieving dataset parameters:\", e)\n",
    "    \n",
    "# ✅ Create cleaned DataLoaders\n",
    "train_dataloader_cleaned = train_dataset_cleaned.to_dataloader(batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader_cleaned = val_dataset_cleaned.to_dataloader(batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"✅ Cleaned DataLoaders created successfully!\")\n",
    "\n",
    "# ✅ Check Before Iteration\n",
    "print(\"\\n🔍 Checking if train_dataloader_cleaned is properly initialized...\")\n",
    "\n",
    "if hasattr(train_dataloader_cleaned, '__len__'):\n",
    "    print(f\"   - DataLoader Length: {len(train_dataloader_cleaned)}\")\n",
    "else:\n",
    "    print(\"   - ❌ Cannot determine DataLoader length!\")\n",
    "\n",
    "# ✅ Check if dataset exists in DataLoader\n",
    "if hasattr(train_dataloader_cleaned, 'dataset'):\n",
    "    print(f\"   - DataLoader dataset type: {type(train_dataloader_cleaned.dataset)}\")\n",
    "    print(f\"   - Dataset Length: {len(train_dataloader_cleaned.dataset) if hasattr(train_dataloader_cleaned.dataset, '__len__') else 'Unknown'}\")\n",
    "else:\n",
    "    print(\"   - ❌ DataLoader has no dataset assigned!\")\n",
    "\n",
    "# ✅ Print the first few items directly from train_dataset_cleaned BEFORE `.to_dataloader()`\n",
    "print(\"\\n🔍 Checking `train_dataset_cleaned` BEFORE DataLoader creation...\")\n",
    "\n",
    "try:\n",
    "    first_items = train_dataset_cleaned[:5]  # Try fetching first 5 records\n",
    "    print(\"✅ Successfully fetched first items from train_dataset_cleaned:\")\n",
    "    print(first_items)\n",
    "except Exception as e:\n",
    "    print(\"❌ Error fetching first records from train_dataset_cleaned:\", e)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     print(\"\\n🚀 Attempting to fetch first batch...\")\n",
    "#     for i, batch in enumerate(train_dataloader_cleaned):\n",
    "#         print(f\"✅ Successfully fetched batch {i+1}\")\n",
    "#         print(\"🔹 Batch Keys:\", batch.keys())\n",
    "\n",
    "#         for key, value in batch.items():\n",
    "#             print(f\"   🔹 {key}: Shape = {value.shape if isinstance(value, torch.Tensor) else type(value)}\")\n",
    "        \n",
    "#         break  # Only print first batch\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"❌ Error fetching batch:\", e)\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Step 6: Train the Model\n",
    "print(\"\\n🚀 Training model...\")\n",
    "\n",
    "try:\n",
    "    trainer.fit(\n",
    "        model=tft_lightning,  \n",
    "        train_dataloaders=train_dataloader_cleaned,  # ✅ Using cleaned DataLoader\n",
    "        val_dataloaders=val_dataloader_cleaned,\n",
    "    )\n",
    "    print(\"✅ Training complete.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Training failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer (TFT) Model Findings  \n",
    "\n",
    "## Challenges Encountered  \n",
    "- **High Computational Requirements**: TFT requires a **large amount of memory and processing power**, making it challenging to train efficiently on our dataset.  \n",
    "- **Sensitivity to Data Quality**: TFT is highly dependent on **clean, structured sequential data**, and any missing values or inconsistencies **significantly impact training stability**.  \n",
    "- **Training Complexity**: Unlike LSTMs/GRUs, **TFT needs careful tuning** of hyperparameters, leading to longer experimentation times.  \n",
    "\n",
    "## Final Decision  \n",
    "Due to the **computational cost and sensitivity**, TFT was not fully trained for deployment, but **remains a strong candidate for future research** if given more time and resources.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau Dashboard Overview\n",
    "\n",
    "## Purpose  \n",
    "The **Tableau Dashboard** serves as an interactive visualization tool to compare the performance of different machine learning models (GRU, LSTM) in predicting **road conditions** based on vehicle sensor data.  \n",
    "\n",
    "## Key Features  \n",
    "- **Time-Series Visualization**: Displays probability trends for different road conditions (Asphalt, Cobblestone, Dirt) for both GRU and LSTM models.  \n",
    "- **Interactivity**: Users can filter by vehicle type, scenario, and road conditions to analyze performance across different conditions.  \n",
    "- **Comparative Analysis**: Side-by-side plots allow for direct comparisons between GRU and LSTM models.  \n",
    "- **KPIs**: Displays **average confidence scores** for both models and identifies the most frequently predicted road condition.  \n",
    "\n",
    "## Insights  \n",
    "- GRU and LSTM show similar prediction trends, but **GRU exhibited slightly higher confidence** in some scenarios.  \n",
    "- Filtering by individual vehicles allows for **detailed per-vehicle analysis** of road condition predictions.  \n",
    "- The dashboard serves as an effective tool for model evaluation, data exploration, and potential real-world applications.  \n",
    "\n",
    "## Tableau Dashboard\n",
    "\n",
    "<img src=\"../docs/tableau-dashboard.png\" alt=\"Image Description\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Future Work & Real-World Applications  \n",
    "\n",
    "## 🔄 Potential Enhancements  \n",
    "- **Refining Data Cleaning**: Improve feature engineering for better model performance and accuracy.  \n",
    "- **Adding More Sensors**: Integrating additional sensors like **brake pressure, suspension type,** and **road friction** could lead to **more precise terrain classification**.  \n",
    "- **Exploring Additional ML Models**: Future iterations can explore **TFT**, **hybrid models**, and **attention-based architectures** to enhance predictive accuracy.  \n",
    "- **Extending the Dataset**: Expanding the dataset to include **more diverse road types, environmental conditions, and extreme terrains** for better generalization.  \n",
    "\n",
    "## 🌍 Real-World Applications  \n",
    "- **🚧 City Infrastructure & Road Maintenance**  \n",
    "  - The predicted road condition data could be integrated into **smart city IoT systems** to help **detect road damage** and **schedule maintenance proactively**.  \n",
    "- **🚗 Vehicle & Tire Optimization**  \n",
    "  - By analyzing vehicle behavior on different terrains, **automakers** can recommend **optimized tires and suspension settings** for enhanced **stability and safety**.  \n",
    "- **🤖 Autonomous Vehicles**  \n",
    "  - Road condition predictions can help **self-driving cars** adjust their driving patterns dynamically based on real-time road feedback, improving adaptability and safety.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Final Thoughts**\n",
    "This project demonstrates **not only predictive modeling** but also **real-world applications** in:  \n",
    "✅ **Smart Infrastructure Development & Road Safety**  \n",
    "✅ **Connected Vehicle Systems & IoT Integration**  \n",
    "✅ **Optimized Vehicle Performance & Manufacturing Insights**  \n",
    "\n",
    "With **continued refinement** and **future iterations**, this project has **the potential to revolutionize road safety, infrastructure planning, and autonomous vehicle intelligence**. 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
