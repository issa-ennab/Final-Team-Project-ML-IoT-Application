{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer (TFT) Attempt\n",
    "\n",
    "### Why We Considered It:\n",
    "- TFT is a **state-of-the-art deep learning model** for **sequential data forecasting**.\n",
    "- It integrates **multiple time-series features** and **handles long-range dependencies** better than traditional RNN-based models (LSTM/GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_forecasting\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "MPS Available: True\n",
      "MPS Built: True\n",
      "Using device: mps\n",
      "PyTorch Forecasting Installed: Success\n",
      "PyTorch Lightning Version: 2.5.0.post0\n"
     ]
    }
   ],
   "source": [
    "# Print PyTorch version\n",
    "print(torch.__version__)\n",
    "\n",
    "# Check if Apple Metal GPU backend (MPS) is available\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "print(\"MPS Built:\", torch.backends.mps.is_built())\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"PyTorch Forecasting Installed:\", \"Success\" if 'pytorch_forecasting' in dir() else \"Failed\")\n",
    "print(\"PyTorch Lightning Version:\", pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080905, 81)\n",
      "      timestamp  acc_x_dashboard_left  acc_y_dashboard_left  \\\n",
      "0  1.577219e+09              0.365116              0.167893   \n",
      "1  1.577219e+09              0.392649              0.176273   \n",
      "2  1.577219e+09              0.409408              0.181062   \n",
      "3  1.577219e+09              0.371101              0.164302   \n",
      "4  1.577219e+09              0.390255              0.159514   \n",
      "\n",
      "   acc_z_dashboard_left  acc_x_above_suspension_left  \\\n",
      "0              9.793961                     0.327626   \n",
      "1              9.771216                     0.381496   \n",
      "2              9.732909                     0.283333   \n",
      "3              9.749668                     0.314458   \n",
      "4              9.869378                     0.344385   \n",
      "\n",
      "   acc_y_above_suspension_left  acc_z_above_suspension_left  \\\n",
      "0                     0.172733                     9.781861   \n",
      "1                     0.189492                     9.699261   \n",
      "2                     0.182310                     9.807000   \n",
      "3                     0.230194                     9.739963   \n",
      "4                     0.202660                     9.762708   \n",
      "\n",
      "   acc_x_below_suspension_left  acc_y_below_suspension_left  \\\n",
      "0                     0.024797                     0.172611   \n",
      "1                     0.024797                     0.194158   \n",
      "2                     0.003249                     0.227677   \n",
      "3                     0.005643                     0.172611   \n",
      "4                     0.005643                     0.200144   \n",
      "\n",
      "   acc_z_below_suspension_left  ...  speed_bump_cobblestone  good_road_left  \\\n",
      "0                     9.793824  ...                       0               1   \n",
      "1                     9.842905  ...                       0               1   \n",
      "2                     9.888395  ...                       0               1   \n",
      "3                     9.871635  ...                       0               1   \n",
      "4                     9.860862  ...                       0               1   \n",
      "\n",
      "   regular_road_left  bad_road_left  good_road_right  regular_road_right  \\\n",
      "0                  0              0                1                   0   \n",
      "1                  0              0                1                   0   \n",
      "2                  0              0                1                   0   \n",
      "3                  0              0                1                   0   \n",
      "4                  0              0                1                   0   \n",
      "\n",
      "   bad_road_right  experiment_id             vehicle    scenario  \n",
      "0               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "1               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "2               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "3               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "4               0          PVS 1  Volkswagen Saveiro  Scenario 1  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned master dataset\n",
    "df = pd.read_csv('dataset/cleaned_master_dataset.csv')\n",
    "\n",
    "# Quick check\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some EDA here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ex: Quick EDA - Visualize vibration data or vehicle-specific trends\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x='scenario', y='acc_x_dashboard_left', data=df)\n",
    "plt.title('Dashboard Acceleration X by Scenario')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Starting Data Preprocessing...\n",
      "‚úîÔ∏è Timestamp dtype: int64\n",
      "\n",
      "üîπ Splitting Data...\n",
      "\n",
      "üîπ Filtering sequences shorter than required length...\n",
      "‚úÖ After filtering: 864724 training rows, 216181 validation rows\n",
      "\n",
      "üîπ Checking unique sequence lengths per vehicle...\n",
      "count       3.000000\n",
      "mean     2884.000000\n",
      "std      1393.818137\n",
      "min      1276.000000\n",
      "25%      2452.500000\n",
      "50%      3629.000000\n",
      "75%      3688.000000\n",
      "max      3747.000000\n",
      "Name: timestamp, dtype: float64\n",
      "count       1.0\n",
      "mean     2164.0\n",
      "std         NaN\n",
      "min      2164.0\n",
      "25%      2164.0\n",
      "50%      2164.0\n",
      "75%      2164.0\n",
      "max      2164.0\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "üîπ Checking for empty columns in train and validation sets...\n",
      "‚ùå Empty columns in train set: ['activity']\n",
      "‚ùå Empty columns in validation set: ['activity']\n",
      "üöÄ Removing empty column 'activity' from train and validation sets.\n",
      "\n",
      "üîπ Checking if `time_varying_unknown_reals` columns contain data...\n",
      "üîπ acc_x_dashboard_left - Missing values: 0 / 864724\n",
      "üîπ acc_y_dashboard_left - Missing values: 0 / 864724\n",
      "\n",
      "üîπ Checking for empty sequences before creating TimeSeriesDataSet...\n",
      "‚ùå Empty sequences in training set: 0\n",
      "‚ùå Empty sequences in validation set: 0\n",
      "\n",
      "üîπ Creating TimeSeriesDataSet for training & validation...\n",
      "\n",
      "‚úÖ Final dataset sizes:\n",
      "üìä Train dataset size: 851585\n",
      "üìä Validation dataset size: 211387\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer, NaNLabelEncoder\n",
    "\n",
    "# üìå 1. DATA PREPROCESSING\n",
    "print(\"üîπ Starting Data Preprocessing...\")\n",
    "\n",
    "# ‚úÖ Copy original dataset to avoid modifications\n",
    "master_df = df.copy()\n",
    "\n",
    "# ‚úÖ Convert timestamp to integer index\n",
    "master_df[\"timestamp\"] = master_df[\"timestamp\"].astype(int)\n",
    "\n",
    "# ‚úÖ Handle missing values in target column\n",
    "master_df[\"speed_meters_per_second\"] = master_df[\"speed_meters_per_second\"].ffill().bfill()\n",
    "\n",
    "# ‚úÖ Ensure vehicle column has no missing values\n",
    "master_df[\"vehicle\"] = master_df[\"vehicle\"].fillna(\"unknown\")\n",
    "\n",
    "# ‚úÖ Print timestamp dtype for verification\n",
    "print(f\"‚úîÔ∏è Timestamp dtype: {master_df['timestamp'].dtype}\")  # Should print 'int64'\n",
    "\n",
    "# üìå 2. SPLITTING DATA INTO TRAIN & VALIDATION\n",
    "print(\"\\nüîπ Splitting Data...\")\n",
    "\n",
    "# ‚úÖ Define time series parameters\n",
    "max_prediction_length = 5  # Future steps to predict\n",
    "max_encoder_length = 15  # History length\n",
    "\n",
    "# ‚úÖ Split dataset manually (80% train, 20% validation)\n",
    "train_size = int(len(master_df) * 0.8)\n",
    "train_df = master_df.iloc[:train_size]\n",
    "val_df = master_df.iloc[train_size:]\n",
    "\n",
    "# ‚úÖ Remove fully empty sequences\n",
    "train_df = train_df.dropna(how=\"all\")\n",
    "val_df = val_df.dropna(how=\"all\")\n",
    "\n",
    "# üìå 3. FILTERING SEQUENCES\n",
    "print(\"\\nüîπ Filtering sequences shorter than required length...\")\n",
    "train_df = train_df.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "val_df = val_df.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "print(f\"‚úÖ After filtering: {len(train_df)} training rows, {len(val_df)} validation rows\")\n",
    "\n",
    "# üìå 4. CHECKING UNIQUE TIMESTAMP COUNTS\n",
    "print(\"\\nüîπ Checking unique sequence lengths per vehicle...\")\n",
    "print(train_df.groupby(\"vehicle\")[\"timestamp\"].nunique().describe())\n",
    "print(val_df.groupby(\"vehicle\")[\"timestamp\"].nunique().describe())\n",
    "\n",
    "# üìå 5. DETECTING EMPTY COLUMNS\n",
    "print(\"\\nüîπ Checking for empty columns in train and validation sets...\")\n",
    "empty_columns_train = train_df.columns[train_df.isna().all()]\n",
    "empty_columns_val = val_df.columns[val_df.isna().all()]\n",
    "print(f\"‚ùå Empty columns in train set: {list(empty_columns_train)}\")\n",
    "print(f\"‚ùå Empty columns in validation set: {list(empty_columns_val)}\")\n",
    "\n",
    "# ‚úÖ Removing completely empty columns\n",
    "if \"activity\" in train_df.columns:\n",
    "    print(\"üöÄ Removing empty column 'activity' from train and validation sets.\")\n",
    "    train_df = train_df.drop(columns=[\"activity\"])\n",
    "    val_df = val_df.drop(columns=[\"activity\"])\n",
    "\n",
    "# üìå 6. VERIFYING KEY COLUMNS HAVE DATA\n",
    "print(\"\\nüîπ Checking if `time_varying_unknown_reals` columns contain data...\")\n",
    "for col in [\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"]:\n",
    "    print(f\"üîπ {col} - Missing values: {train_df[col].isna().sum()} / {len(train_df)}\")\n",
    "\n",
    "# üìå 7. VERIFYING EMPTY SEQUENCES\n",
    "print(\"\\nüîπ Checking for empty sequences before creating TimeSeriesDataSet...\")\n",
    "empty_sequences_train = train_df.groupby(\"vehicle\").filter(lambda x: len(x) == 0)\n",
    "empty_sequences_val = val_df.groupby(\"vehicle\").filter(lambda x: len(x) == 0)\n",
    "print(f\"‚ùå Empty sequences in training set: {len(empty_sequences_train)}\")\n",
    "print(f\"‚ùå Empty sequences in validation set: {len(empty_sequences_val)}\")\n",
    "\n",
    "# üìå 8. CREATING TIME SERIES DATASETS\n",
    "print(\"\\nüîπ Creating TimeSeriesDataSet for training & validation...\")\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},  # Handles missing categories\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet(\n",
    "    val_df,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},\n",
    ")\n",
    "\n",
    "# üìå 9. FINAL OUTPUT\n",
    "print(\"\\n‚úÖ Final dataset sizes:\")\n",
    "print(f\"üìä Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"üìä Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Checking for empty features in train dataset...\n",
      "üîπ timestamp: Missing values = 0, Zero values = 0\n",
      "üîπ acc_x_dashboard_left: Missing values = 0, Zero values = 93\n",
      "üîπ acc_y_dashboard_left: Missing values = 0, Zero values = 21\n",
      "üîπ acc_z_dashboard_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_x_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_y_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_z_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_x_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_y_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_z_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_x_dashboard_left: Missing values = 0, Zero values = 1053\n",
      "üîπ gyro_y_dashboard_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_z_dashboard_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_x_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_y_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_z_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_x_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_y_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ gyro_z_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ mag_x_dashboard_left: Missing values = 0, Zero values = 1262\n",
      "üîπ mag_y_dashboard_left: Missing values = 0, Zero values = 1536\n",
      "üîπ mag_z_dashboard_left: Missing values = 0, Zero values = 5459\n",
      "üîπ mag_x_above_suspension_left: Missing values = 0, Zero values = 1247\n",
      "üîπ mag_y_above_suspension_left: Missing values = 0, Zero values = 418\n",
      "üîπ mag_z_above_suspension_left: Missing values = 0, Zero values = 613\n",
      "üîπ temp_dashboard_left: Missing values = 0, Zero values = 3\n",
      "üîπ temp_above_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ temp_below_suspension_left: Missing values = 0, Zero values = 3\n",
      "üîπ acc_x_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_y_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_z_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_x_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_y_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_z_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_x_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_y_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ acc_z_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_x_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_y_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_z_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_x_above_suspension_right: Missing values = 0, Zero values = 694\n",
      "üîπ gyro_y_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_z_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_x_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_y_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ gyro_z_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ mag_x_dashboard_right: Missing values = 0, Zero values = 1569\n",
      "üîπ mag_y_dashboard_right: Missing values = 0, Zero values = 1709\n",
      "üîπ mag_z_dashboard_right: Missing values = 0, Zero values = 9063\n",
      "üîπ mag_x_above_suspension_right: Missing values = 0, Zero values = 322\n",
      "üîπ mag_y_above_suspension_right: Missing values = 0, Zero values = 768\n",
      "üîπ mag_z_above_suspension_right: Missing values = 0, Zero values = 380\n",
      "üîπ temp_dashboard_right: Missing values = 0, Zero values = 1\n",
      "üîπ temp_above_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ temp_below_suspension_right: Missing values = 0, Zero values = 1\n",
      "üîπ elevation: Missing values = 859343, Zero values = 0\n",
      "üîπ speed_meters_per_second: Missing values = 0, Zero values = 0\n",
      "üîπ satellites: Missing values = 859343, Zero values = 0\n",
      "üîπ hdop: Missing values = 859345, Zero values = 0\n",
      "üîπ vdop: Missing values = 859349, Zero values = 0\n",
      "üîπ pdop: Missing values = 859349, Zero values = 0\n",
      "üîπ distance_meters: Missing values = 859343, Zero values = 0\n",
      "üîπ elapsed_time_seconds: Missing values = 859343, Zero values = 0\n",
      "üîπ paved_road: Missing values = 0, Zero values = 231253\n",
      "üîπ unpaved_road: Missing values = 0, Zero values = 633471\n",
      "üîπ dirt_road: Missing values = 0, Zero values = 633471\n",
      "üîπ cobblestone_road: Missing values = 0, Zero values = 594507\n",
      "üîπ asphalt_road: Missing values = 0, Zero values = 501469\n",
      "üîπ no_speed_bump: Missing values = 0, Zero values = 14628\n",
      "üîπ speed_bump_asphalt: Missing values = 0, Zero values = 858471\n",
      "üîπ speed_bump_cobblestone: Missing values = 0, Zero values = 856348\n",
      "üîπ good_road_left: Missing values = 0, Zero values = 507386\n",
      "üîπ regular_road_left: Missing values = 0, Zero values = 503230\n",
      "üîπ bad_road_left: Missing values = 0, Zero values = 718832\n",
      "üîπ good_road_right: Missing values = 0, Zero values = 507570\n",
      "üîπ regular_road_right: Missing values = 0, Zero values = 499146\n",
      "üîπ bad_road_right: Missing values = 0, Zero values = 722732\n",
      "üîπ experiment_id: Missing values = 0, Zero values = 0\n",
      "üîπ vehicle: Missing values = 0, Zero values = 0\n",
      "üîπ scenario: Missing values = 0, Zero values = 0\n",
      "\n",
      "‚úÖ Checking unique sequence lengths in train dataset (filtered):\n",
      "count       3.000000\n",
      "mean     2884.000000\n",
      "std      1393.818137\n",
      "min      1276.000000\n",
      "25%      2452.500000\n",
      "50%      3629.000000\n",
      "75%      3688.000000\n",
      "max      3747.000000\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "‚úÖ Checking unique sequence lengths in validation dataset (filtered):\n",
      "count       1.0\n",
      "mean     2164.0\n",
      "std         NaN\n",
      "min      2164.0\n",
      "25%      2164.0\n",
      "50%      2164.0\n",
      "75%      2164.0\n",
      "max      2164.0\n",
      "Name: timestamp, dtype: float64\n",
      "\n",
      "‚úÖ Train DataLoader batches: 6654\n",
      "‚úÖ Validation DataLoader batches: 1652\n",
      "\n",
      "‚úÖ Checking first batch from DataLoader...\n",
      "‚ùå Error fetching batch: stack expects each tensor to be equal size, but got [1808, 0] at entry 0 and [1892, 0] at entry 1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ‚úÖ Step 0: Check for empty features in train_df before DataLoader\n",
    "print(\"\\nüîπ Checking for empty features in train dataset...\")\n",
    "for key in train_df.columns:\n",
    "    num_missing = train_df[key].isna().sum()\n",
    "    num_zeros = (train_df[key] == 0).sum()\n",
    "    print(f\"üîπ {key}: Missing values = {num_missing}, Zero values = {num_zeros}\")\n",
    "\n",
    "# ‚úÖ Step 1: Check unique sequence lengths\n",
    "print(\"\\n‚úÖ Checking unique sequence lengths in train dataset (filtered):\")\n",
    "train_sequence_lengths = train_df.groupby(\"vehicle\")[\"timestamp\"].nunique()\n",
    "print(train_sequence_lengths.describe())  \n",
    "\n",
    "print(\"\\n‚úÖ Checking unique sequence lengths in validation dataset (filtered):\")\n",
    "val_sequence_lengths = val_df.groupby(\"vehicle\")[\"timestamp\"].nunique()\n",
    "print(val_sequence_lengths.describe())\n",
    "\n",
    "# ‚úÖ Step 2: Define batch size\n",
    "batch_size = 128\n",
    "\n",
    "# ‚úÖ Step 3: Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\n‚úÖ Train DataLoader batches: {len(train_dataloader)}\")\n",
    "print(f\"‚úÖ Validation DataLoader batches: {len(val_dataloader)}\")\n",
    "\n",
    "# ‚úÖ Step 4: Debug DataLoader fetching\n",
    "print(\"\\n‚úÖ Checking first batch from DataLoader...\")\n",
    "\n",
    "try:\n",
    "    first_batch = next(iter(train_dataloader))\n",
    "    print(\"‚úÖ Successfully fetched a batch\")\n",
    "    print(\"üîπ Batch Keys:\", first_batch.keys())\n",
    "\n",
    "    for key, value in first_batch.items():\n",
    "        print(f\"   üîπ {key}: Shape = {value.shape if isinstance(value, torch.Tensor) else type(value)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error fetching batch:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Starting Aggressive Data Cleaning Process...\n",
      "üöÄ Dropping high-missing-value columns: ['elevation', 'satellites', 'hdop', 'vdop', 'pdop', 'distance_meters', 'elapsed_time_seconds']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  val_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/3y/9mpx5xp50f9chfv2mgfnsmmr0000gn/T/ipykernel_32121/1449649126.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  val_df_cleaned.fillna(method=\"bfill\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Verifying sequence lengths after aggressive cleaning...\n",
      "‚úÖ After cleaning: 864724 training rows, 216181 validation rows\n",
      "\n",
      "üîπ Creating new TimeSeriesDataSet with aggressively cleaned data...\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: group_ids (1449649126.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[69], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    group_ids=[\"vehicle\"],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: group_ids\n"
     ]
    }
   ],
   "source": [
    "# üìå CELL 3: Aggressive Data Cleaning & Preparing Data for TFT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüîπ Starting Aggressive Data Cleaning Process...\")\n",
    "\n",
    "# ‚úÖ Step 1: Identify columns to drop (ONLY if completely useless)\n",
    "high_missing_cols = [\"elevation\", \"satellites\", \"hdop\", \"vdop\", \"pdop\", \n",
    "                     \"distance_meters\", \"elapsed_time_seconds\"]\n",
    "\n",
    "print(f\"üöÄ Dropping high-missing-value columns: {high_missing_cols}\")\n",
    "\n",
    "train_df_cleaned = train_df.drop(columns=high_missing_cols, errors=\"ignore\")\n",
    "val_df_cleaned = val_df.drop(columns=high_missing_cols, errors=\"ignore\")\n",
    "\n",
    "# ‚úÖ Step 2: Fill remaining missing values intelligently\n",
    "# Forward-fill first, then back-fill as a safety net\n",
    "train_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
    "train_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "val_df_cleaned.fillna(method=\"ffill\", inplace=True)\n",
    "val_df_cleaned.fillna(method=\"bfill\", inplace=True)\n",
    "\n",
    "# **NEW**: Fill any remaining NaNs with the median value of each column\n",
    "for col in train_df_cleaned.columns:\n",
    "    if train_df_cleaned[col].isna().sum() > 0:\n",
    "        median_value = train_df_cleaned[col].median()\n",
    "        train_df_cleaned[col].fillna(median_value, inplace=True)\n",
    "\n",
    "for col in val_df_cleaned.columns:\n",
    "    if val_df_cleaned[col].isna().sum() > 0:\n",
    "        median_value = val_df_cleaned[col].median()\n",
    "        val_df_cleaned[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# ‚úÖ Step 3: Replace zero values in key features to prevent model breakage\n",
    "zero_replacement_cols = [\"speed_meters_per_second\", \"acc_x_dashboard_left\", \"acc_y_dashboard_left\"]\n",
    "for col in zero_replacement_cols:\n",
    "    train_df_cleaned[col] = train_df_cleaned[col].replace(0, train_df_cleaned[col].median())\n",
    "    val_df_cleaned[col] = val_df_cleaned[col].replace(0, val_df_cleaned[col].median())\n",
    "\n",
    "# ‚úÖ Step 4: Ensure sequences are still valid\n",
    "print(\"\\nüîπ Verifying sequence lengths after aggressive cleaning...\")\n",
    "\n",
    "train_df_cleaned = train_df_cleaned.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "val_df_cleaned = val_df_cleaned.groupby(\"vehicle\").filter(lambda x: len(x) >= max_encoder_length + max_prediction_length)\n",
    "\n",
    "print(f\"‚úÖ After cleaning: {len(train_df_cleaned)} training rows, {len(val_df_cleaned)} validation rows\")\n",
    "\n",
    "# ‚úÖ Step 5: Re-create TimeSeriesDataSet with cleaned data\n",
    "print(\"\\nüîπ Creating new TimeSeriesDataSet with aggressively cleaned data...\")\n",
    "\n",
    "train_dataset_cleaned = TimeSeriesDataSet(\n",
    "    train_df_cleaned,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    static_categoricals=[\"vehicle\"],  # ‚úÖ Add this line to define `vehicle` as a categorical feature\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    group_ids=[\"vehicle\"],\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},  # Handles missing categories\n",
    ")\n",
    "\n",
    "val_dataset_cleaned = TimeSeriesDataSet(\n",
    "    val_df_cleaned,\n",
    "    time_idx=\"timestamp\",\n",
    "    target=\"speed_meters_per_second\",\n",
    "    group_ids=[\"vehicle\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"timestamp\"],\n",
    "    time_varying_unknown_reals=[\"acc_x_dashboard_left\", \"acc_y_dashboard_left\"],\n",
    "    static_categoricals=[\"vehicle\"],  # ‚úÖ Add this line here too\n",
    "    target_normalizer=GroupNormalizer(groups=[\"vehicle\"]),\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    group_ids=[\"vehicle\"],\n",
    "    categorical_encoders={\"vehicle\": NaNLabelEncoder(add_nan=True)},\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 6: Final Dataset Validation\n",
    "print(\"\\n‚úÖ Final cleaned dataset sizes:\")\n",
    "print(f\"üìä Train dataset size: {len(train_dataset_cleaned)}\")\n",
    "print(f\"üìä Validation dataset size: {len(val_dataset_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Extracting a SMALL dataset sample for debugging...\n",
      "\n",
      "üîç Checking column lengths in Train dataset (Debug Sample)...\n",
      "üîπ Column: reals, Shape: torch.Size([864724, 6])\n",
      "üîπ Column: categoricals, Shape: torch.Size([864724, 1])\n",
      "üîπ Column: groups, Shape: torch.Size([864724, 1])\n",
      "üîπ Column: target, Shape: 1\n",
      "‚ùå Warning: Column weight is None!\n",
      "üîπ Column: time, Shape: torch.Size([864724])\n",
      "\n",
      "üîç Checking column lengths in Validation dataset (Debug Sample)...\n",
      "üîπ Column: reals, Shape: torch.Size([216181, 6])\n",
      "üîπ Column: categoricals, Shape: torch.Size([216181, 1])\n",
      "üîπ Column: groups, Shape: torch.Size([216181, 1])\n",
      "üîπ Column: target, Shape: 1\n",
      "‚ùå Warning: Column weight is None!\n",
      "üîπ Column: time, Shape: torch.Size([216181])\n",
      "üîç BEFORE FIX: `train.categoricals` shape = torch.Size([864724, 1])\n",
      "üîç BEFORE FIX: `val.categoricals` shape = torch.Size([216181, 1])\n",
      "‚úÖ AFTER FIX: `train.categoricals` shape = torch.Size([864724, 1])\n",
      "‚úÖ AFTER FIX: `val.categoricals` shape = torch.Size([216181, 1])\n",
      "\n",
      "üîç Final dataset keys before DataLoader creation:\n",
      "üîπ Train dataset keys: ['reals', 'categoricals', 'groups', 'target', 'weight', 'time']\n",
      "üîπ Validation dataset keys: ['reals', 'categoricals', 'groups', 'target', 'weight', 'time']\n",
      "\n",
      "üîç Checking for empty or incorrect columns before DataFrame creation...\n",
      "üîÑ Fixing `target` in train dataset: Extracting tensor...\n",
      "üîÑ Converting `target` tensor to NumPy array in train dataset...\n",
      "üîÑ Fixing `target` in val dataset: Extracting tensor...\n",
      "üîÑ Converting `target` tensor to NumPy array in val dataset...\n",
      "\n",
      "‚úÖ `target` column successfully fixed for both datasets!\n",
      "\n",
      "üîç Checking dataset length consistency before trimming...\n",
      "\n",
      "üîπ Train dataset keys: ['reals', 'categoricals', 'groups', 'target', 'time']\n",
      "üîπ Validation dataset keys: ['reals', 'categoricals', 'groups', 'target', 'time']\n",
      "\n",
      "üîç Train dataset column lengths:\n",
      "   - `reals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `categoricals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `groups`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `target`: Length = 864724 | Shape = (864724,)\n",
      "   - `time`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "\n",
      "üîç Validation dataset column lengths:\n",
      "   - `reals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `categoricals`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `groups`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "   - `target`: Length = 216181 | Shape = (216181,)\n",
      "   - `time`: Type = <class 'torch.Tensor'> (Not an ndarray)\n",
      "\n",
      "üîç Inspecting first 5 records for each feature in TRAIN dataset:\n",
      "\n",
      "üîπ Feature: `reals`\n",
      "[[-1.1649995  -1.166046    0.37036544  0.          0.2901575   0.17322966]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.04296927  0.4961055 ]\n",
      " [-1.1649995  -1.166046    0.37036544  0.         -0.04819235  0.33333337]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.21652696 -0.04157615]\n",
      " [-1.1649995  -1.166046    0.37036544  0.          0.25158912  0.2065846 ]]\n",
      "\n",
      "üîπ Feature: `categoricals`\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "üîπ Feature: `groups`\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "üîπ Feature: `target`\n",
      "[22.576147 22.576147 22.576147 22.576147 22.576147]\n",
      "\n",
      "üîπ Feature: `time`\n",
      "[1577306803 1577306803 1577306803 1577306803 1577306803]\n",
      "\n",
      "‚úÖ Final `categoricals` Shape in Train Dataset: torch.Size([864724, 1])\n",
      "\n",
      "üîç Inspecting first 5 records for each feature in VALIDATION dataset:\n",
      "\n",
      "üîπ Feature: `reals`\n",
      "[[ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.2830735e-01 -2.4845469e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.2072284e-01 -2.2991690e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -8.9322901e-01 -2.3918580e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -8.9417708e-01 -2.3238860e-01]\n",
      " [ 0.0000000e+00  8.8817842e-16 -1.8225631e+00  0.0000000e+00\n",
      "  -9.3778795e-01 -2.5710565e-01]]\n",
      "\n",
      "üîπ Feature: `categoricals`\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "üîπ Feature: `groups`\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "üîπ Feature: `target`\n",
      "[0.7602653 0.7602653 0.7602653 0.7602653 0.7602653]\n",
      "\n",
      "üîπ Feature: `time`\n",
      "[1577396705 1577396705 1577396705 1577396705 1577396705]\n",
      "\n",
      "‚úÖ Feature inspection completed.\n",
      "‚úÖ DataFrame created successfully!\n",
      "\n",
      "üîπ Train dataset sample:\n",
      "           target        time\n",
      "659348   2.115313  1577221418\n",
      "367583   0.013329  1577395479\n",
      "729957   9.086297  1577222124\n",
      "56398    6.685661  1577307367\n",
      "135961   5.780402  1577308639\n",
      "275275   0.022758  1577310339\n",
      "816169  22.576147  1577223941\n",
      "784166  22.576147  1577223621\n",
      "371017  16.763273  1577395514\n",
      "288893   0.022758  1577310476\n",
      "\n",
      "üîπ Validation dataset sample:\n",
      "           target        time\n",
      "183849   2.914004  1577399597\n",
      "131084  21.062319  1577399069\n",
      "162666   8.601702  1577399385\n",
      "200025  19.179893  1577399759\n",
      "24914    0.044819  1577397296\n",
      "166927   7.926495  1577399428\n",
      "205860  21.770510  1577399817\n",
      "20670    0.044819  1577397254\n",
      "133662  22.811634  1577399095\n",
      "60870    0.044819  1577397656\n",
      "\n",
      "üîπ Checking for missing values in Train dataset...\n",
      "target    0\n",
      "time      0\n",
      "dtype: int64\n",
      "\n",
      "üîπ Checking for missing values in Validation dataset...\n",
      "target    0\n",
      "time      0\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Data extraction and alignment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# üìå CELL 4: Debugging Before DataLoader Creation\n",
    "\n",
    "print(\"\\nüîπ Extracting a SMALL dataset sample for debugging...\")\n",
    "\n",
    "# ‚úÖ Set Debugging Sample Size (e.g., 50,000 for performance)\n",
    "DEBUG_SAMPLE_SIZE = 100_000\n",
    "\n",
    "# ‚úÖ Extract a smaller dataset sample instead of full dataset\n",
    "train_data_dict = train_dataset_cleaned.to_dataloader(batch_size=DEBUG_SAMPLE_SIZE).dataset.data\n",
    "val_data_dict = val_dataset_cleaned.to_dataloader(batch_size=DEBUG_SAMPLE_SIZE).dataset.data\n",
    "\n",
    "# ‚úÖ Debug: Check structure of extracted dictionary\n",
    "print(\"\\nüîç Checking column lengths in Train dataset (Debug Sample)...\")\n",
    "for key, value in train_data_dict.items():\n",
    "    if value is None:\n",
    "        print(f\"‚ùå Warning: Column {key} is None!\")\n",
    "    else:\n",
    "        print(f\"üîπ Column: {key}, Shape: {value.shape if hasattr(value, 'shape') else len(value)}\")\n",
    "\n",
    "print(\"\\nüîç Checking column lengths in Validation dataset (Debug Sample)...\")\n",
    "for key, value in val_data_dict.items():\n",
    "    if value is None:\n",
    "        print(f\"‚ùå Warning: Column {key} is None!\")\n",
    "    else:\n",
    "        print(f\"üîπ Column: {key}, Shape: {value.shape if hasattr(value, 'shape') else len(value)}\")\n",
    "\n",
    "# ‚úÖ Step 1: Drop Unnecessary Columns (`reals`, `groups`, `categoricals`)\n",
    "# columns_to_drop = [\"reals\", \"groups\", \"categoricals\"]\n",
    "\n",
    "# for col in columns_to_drop:\n",
    "#     if col in train_data_dict:\n",
    "#         print(f\"üóëÔ∏è Dropping `{col}` from Train dataset...\")\n",
    "#         del train_data_dict[col]\n",
    "#     if col in val_data_dict:\n",
    "#         print(f\"üóëÔ∏è Dropping `{col}` from Validation dataset...\")\n",
    "#         del val_data_dict[col]\n",
    "\n",
    "# print(\"\\n‚úÖ `reals`, `groups`, and `categoricals` successfully removed from both datasets!\")\n",
    "\n",
    "# ‚úÖ Print Before Fixing `categoricals`\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"categoricals\" in dataset_dict:\n",
    "        print(f\"üîç BEFORE FIX: `{dataset_name}.categoricals` shape = {dataset_dict['categoricals'].shape}\")\n",
    "\n",
    "# ‚úÖ Ensure `categoricals` is 2D and has at least one column\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"categoricals\" in dataset_dict:\n",
    "        if dataset_dict[\"categoricals\"].size == 0:  # If it's an empty (N,0) tensor\n",
    "            dataset_dict[\"categoricals\"] = torch.zeros((len(dataset_dict[\"target\"]), 1))  # Add one column of zeros\n",
    "        \n",
    "        print(f\"‚úÖ AFTER FIX: `{dataset_name}.categoricals` shape = {dataset_dict['categoricals'].shape}\")\n",
    "\n",
    "\n",
    "# ‚úÖ Final check: Ensure `reals` is removed before creating DataLoaders\n",
    "print(\"\\nüîç Final dataset keys before DataLoader creation:\")\n",
    "print(\"üîπ Train dataset keys:\", list(train_data_dict.keys()))\n",
    "print(\"üîπ Validation dataset keys:\", list(val_data_dict.keys()))\n",
    "\n",
    "\n",
    "# ‚úÖ Remove NoneType values before checking length\n",
    "train_data_dict = {k: v for k, v in train_data_dict.items() if v is not None}\n",
    "val_data_dict = {k: v for k, v in val_data_dict.items() if v is not None}\n",
    "\n",
    "# üö® **Step 2: Detect & Remove Empty Columns**\n",
    "print(\"\\nüîç Checking for empty or incorrect columns before DataFrame creation...\")\n",
    "columns_to_remove = []\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    for key, value in dataset_dict.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"   üîπ `{dataset_name}.{key}`: Shape = {value.shape}\")\n",
    "\n",
    "            # üö® Remove empty or malformed columns\n",
    "            if value.size == 0 or value.shape in [(), (1, 0)]:\n",
    "                print(f\"üö® WARNING: `{key}` in {dataset_name} is EMPTY or malformed! Removing column.\")\n",
    "                columns_to_remove.append((dataset_name, key))\n",
    "\n",
    "# üö® **Remove Problematic Columns**\n",
    "for dataset_name, key in columns_to_remove:\n",
    "    if dataset_name == \"train\":\n",
    "        del train_data_dict[key]\n",
    "    else:\n",
    "        del val_data_dict[key]\n",
    "\n",
    "# ‚úÖ Step 3: Fix `target` Column (Flatten & Convert)\n",
    "for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "    if \"target\" in dataset_dict:\n",
    "        if isinstance(dataset_dict[\"target\"], list) and len(dataset_dict[\"target\"]) == 1:\n",
    "            print(f\"üîÑ Fixing `target` in {dataset_name} dataset: Extracting tensor...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"][0]  # Extract tensor\n",
    "        \n",
    "        if isinstance(dataset_dict[\"target\"], torch.Tensor):\n",
    "            print(f\"üîÑ Converting `target` tensor to NumPy array in {dataset_name} dataset...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"].cpu().numpy()  # Convert to NumPy\n",
    "        \n",
    "        if dataset_dict[\"target\"].ndim > 1:\n",
    "            print(f\"‚ö†Ô∏è `target` in {dataset_name} is multi-dimensional ({dataset_dict['target'].shape}), flattening...\")\n",
    "            dataset_dict[\"target\"] = dataset_dict[\"target\"].reshape(-1)  # Flatten to 1D\n",
    "\n",
    "print(\"\\n‚úÖ `target` column successfully fixed for both datasets!\")\n",
    "\n",
    "# # üö® **Step 3: Fix `groups` & `time` Columns**\n",
    "# for dataset_name, dataset_dict in [(\"train\", train_data_dict), (\"val\", val_data_dict)]:\n",
    "#     for key in dataset_dict.keys():\n",
    "#         if isinstance(dataset_dict[key], np.ndarray):\n",
    "#             # üö® Fix `groups` column\n",
    "#             if key == \"groups\":\n",
    "#                 if dataset_dict[key].ndim == 0 or dataset_dict[key].shape == ():\n",
    "#                     print(f\"‚ö†Ô∏è WARNING: `{key}` in {dataset_name} is scalar! Converting to 1D array...\")\n",
    "#                     dataset_dict[key] = np.array([dataset_dict[key]])  # Convert to array\n",
    "\n",
    "#             # üö® Fix `time` column\n",
    "#             if key == \"time\":\n",
    "#                 if dataset_dict[key].ndim != 1:\n",
    "#                     print(f\"‚ö†Ô∏è WARNING: `{key}` in {dataset_name} is not 1D! Flattening...\")\n",
    "#                     dataset_dict[key] = dataset_dict[key].reshape(-1)  # Force 1D shape\n",
    "            \n",
    "#             # üö® Catch remaining multi-dimensional issues\n",
    "#             if dataset_dict[key].ndim > 1:\n",
    "#                 print(f\"‚ö†Ô∏è Column `{key}` in {dataset_name} is multi-dimensional ({dataset_dict[key].shape}), flattening...\")\n",
    "#                 dataset_dict[key] = dataset_dict[key].reshape(-1)  # Flatten to 1D\n",
    "\n",
    "# ‚úÖ **Step 4: Trim Dataset Lengths for Consistency**\n",
    "print(\"\\nüîç Checking dataset length consistency before trimming...\")\n",
    "\n",
    "# üöÄ Print dataset keys\n",
    "print(\"\\nüîπ Train dataset keys:\", list(train_data_dict.keys()))\n",
    "print(\"üîπ Validation dataset keys:\", list(val_data_dict.keys()))\n",
    "\n",
    "# üöÄ Print each column's length before calculating min length\n",
    "print(\"\\nüîç Train dataset column lengths:\")\n",
    "for key, value in train_data_dict.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"   - `{key}`: Length = {len(value)} | Shape = {value.shape}\")\n",
    "    else:\n",
    "        print(f\"   - `{key}`: Type = {type(value)} (Not an ndarray)\")\n",
    "\n",
    "print(\"\\nüîç Validation dataset column lengths:\")\n",
    "for key, value in val_data_dict.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"   - `{key}`: Length = {len(value)} | Shape = {value.shape}\")\n",
    "    else:\n",
    "        print(f\"   - `{key}`: Type = {type(value)} (Not an ndarray)\")\n",
    "\n",
    "\n",
    "# üöÄ **Step 4.1: Print First 5 Records for Each Column**\n",
    "print(\"\\nüîç Inspecting first 5 records for each feature in TRAIN dataset:\")\n",
    "\n",
    "for key, value in train_data_dict.items():\n",
    "    try:\n",
    "        print(f\"\\nüîπ Feature: `{key}`\")\n",
    "        \n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(value[:5].cpu().numpy())  # Convert tensor to NumPy and print first 5 records\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(value[:5])  # Directly print first 5 records\n",
    "        elif isinstance(value, list):\n",
    "            print(value[:5])  # Print first 5 records if it's a list\n",
    "        else:\n",
    "            print(f\"‚ùå Unexpected data type: {type(value)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing `{key}`:\", e)\n",
    "\n",
    "print(\"\\n‚úÖ Final `categoricals` Shape in Train Dataset:\", train_data_dict[\"categoricals\"].shape)\n",
    "\n",
    "# Step 4.2: Repeat for Validation Dataset\n",
    "print(\"\\nüîç Inspecting first 5 records for each feature in VALIDATION dataset:\")\n",
    "\n",
    "for key, value in val_data_dict.items():\n",
    "    try:\n",
    "        print(f\"\\nüîπ Feature: `{key}`\")\n",
    "        \n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(value[:5].cpu().numpy())  # Convert tensor to NumPy and print first 5 records\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(value[:5])  # Directly print first 5 records\n",
    "        elif isinstance(value, list):\n",
    "            print(value[:5])  # Print first 5 records if it's a list\n",
    "        else:\n",
    "            print(f\"‚ùå Unexpected data type: {type(value)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing `{key}`:\", e)\n",
    "\n",
    "print(\"\\n‚úÖ Feature inspection completed.\")\n",
    "\n",
    "\n",
    "# ‚úÖ Temporarily remove `categoricals` and `groups` before DataFrame conversion \n",
    "# (since Pandas doesn't support 2D arrays)\n",
    "train_data_dict_for_df = {\n",
    "    k: v.cpu().numpy() if isinstance(v, torch.Tensor) else v \n",
    "    for k, v in train_data_dict.items() if k not in [\"reals\", \"categoricals\", \"groups\"]\n",
    "}\n",
    "val_data_dict_for_df = {\n",
    "    k: v.cpu().numpy() if isinstance(v, torch.Tensor) else v \n",
    "    for k, v in val_data_dict.items() if k not in [\"reals\", \"categoricals\", \"groups\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    train_df_debug = pd.DataFrame.from_dict(train_data_dict_for_df).sample(10)\n",
    "    val_df_debug = pd.DataFrame.from_dict(val_data_dict_for_df).sample(10)\n",
    "    print(\"‚úÖ DataFrame created successfully!\")\n",
    "except ValueError as e:\n",
    "    print(\"\\n‚ùå ERROR: Could not create Pandas DataFrame! The dataset is likely empty.\", e)\n",
    "    raise e\n",
    "\n",
    "# ‚úÖ **Step 6: Print Final Debugging Info**\n",
    "print(\"\\nüîπ Train dataset sample:\")\n",
    "print(train_df_debug)\n",
    "\n",
    "print(\"\\nüîπ Validation dataset sample:\")\n",
    "print(val_df_debug)\n",
    "\n",
    "# ‚úÖ **Check for missing values**\n",
    "print(\"\\nüîπ Checking for missing values in Train dataset...\")\n",
    "print(train_df_debug.isna().sum())\n",
    "\n",
    "print(\"\\nüîπ Checking for missing values in Validation dataset...\")\n",
    "print(val_df_debug.isna().sum())\n",
    "\n",
    "print(\"\\n‚úÖ Data extraction and alignment completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Initializing TemporalFusionTransformer model with cleaned data...\n",
      "\n",
      "‚úÖ TemporalFusionTransformer Model Initialized Successfully!\n",
      "TemporalFusionTransformer(\n",
      "  \t\"attention_head_size\":               4\n",
      "  \t\"categorical_groups\":                {}\n",
      "  \t\"causal_attention\":                  True\n",
      "  \t\"dataset_parameters\":                {'time_idx': 'timestamp', 'target': 'speed_meters_per_second', 'group_ids': ['vehicle'], 'weight': None, 'max_encoder_length': 15, 'min_encoder_length': 15, 'min_prediction_idx': 1577218796, 'min_prediction_length': 5, 'max_prediction_length': 5, 'static_categoricals': None, 'static_reals': None, 'time_varying_known_categoricals': None, 'time_varying_known_reals': ['timestamp'], 'time_varying_unknown_categoricals': None, 'time_varying_unknown_reals': ['acc_x_dashboard_left', 'acc_y_dashboard_left'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': True, 'lags': None, 'add_relative_time_idx': True, 'add_target_scales': True, 'add_encoder_length': False, 'target_normalizer': GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['vehicle'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t), 'categorical_encoders': {'vehicle': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__vehicle': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'speed_meters_per_second_center': StandardScaler(), 'speed_meters_per_second_scale': StandardScaler(), 'timestamp': StandardScaler(), 'relative_time_idx': StandardScaler(), 'acc_x_dashboard_left': StandardScaler(), 'acc_y_dashboard_left': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
      "  \t\"dropout\":                           0.1\n",
      "  \t\"embedding_labels\":                  {}\n",
      "  \t\"embedding_paddings\":                ['vehicle']\n",
      "  \t\"embedding_sizes\":                   {}\n",
      "  \t\"hidden_continuous_size\":            16\n",
      "  \t\"hidden_continuous_sizes\":           {}\n",
      "  \t\"hidden_size\":                       64\n",
      "  \t\"learning_rate\":                     0.001\n",
      "  \t\"log_gradient_flow\":                 False\n",
      "  \t\"log_interval\":                      10\n",
      "  \t\"log_val_interval\":                  10\n",
      "  \t\"lstm_layers\":                       1\n",
      "  \t\"max_encoder_length\":                15\n",
      "  \t\"monotone_constaints\":               {}\n",
      "  \t\"monotone_constraints\":              {}\n",
      "  \t\"optimizer\":                         adam\n",
      "  \t\"optimizer_params\":                  None\n",
      "  \t\"output_size\":                       1\n",
      "  \t\"output_transformer\":                GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['vehicle'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t)\n",
      "  \t\"reduce_on_plateau_min_lr\":          1e-05\n",
      "  \t\"reduce_on_plateau_patience\":        4\n",
      "  \t\"reduce_on_plateau_reduction\":       2.0\n",
      "  \t\"share_single_variable_networks\":    False\n",
      "  \t\"static_categoricals\":               []\n",
      "  \t\"static_reals\":                      ['speed_meters_per_second_center', 'speed_meters_per_second_scale']\n",
      "  \t\"time_varying_categoricals_decoder\": []\n",
      "  \t\"time_varying_categoricals_encoder\": []\n",
      "  \t\"time_varying_reals_decoder\":        ['timestamp', 'relative_time_idx']\n",
      "  \t\"time_varying_reals_encoder\":        ['timestamp', 'relative_time_idx', 'acc_x_dashboard_left', 'acc_y_dashboard_left']\n",
      "  \t\"weight_decay\":                      0.0\n",
      "  \t\"x_categoricals\":                    []\n",
      "  \t\"x_reals\":                           ['speed_meters_per_second_center', 'speed_meters_per_second_scale', 'timestamp', 'relative_time_idx', 'acc_x_dashboard_left', 'acc_y_dashboard_left']\n",
      "  (loss): QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
      "  (logging_metrics): ModuleList(\n",
      "    (0): SMAPE()\n",
      "    (1): MAE()\n",
      "    (2): RMSE()\n",
      "    (3): MAPE()\n",
      "  )\n",
      "  (input_embeddings): MultiEmbedding(\n",
      "    (embeddings): ModuleDict()\n",
      "  )\n",
      "  (prescalers): ModuleDict(\n",
      "    (speed_meters_per_second_center): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (speed_meters_per_second_scale): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (acc_x_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "    (acc_y_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "  )\n",
      "  (static_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (speed_meters_per_second_center): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (speed_meters_per_second_scale): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (speed_meters_per_second_center): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (speed_meters_per_second_scale): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (encoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=4, out_features=8, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (timestamp): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (relative_time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (acc_x_dashboard_left): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (acc_y_dashboard_left): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (acc_x_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (acc_y_dashboard_left): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (decoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=64, out_features=2, bias=False)\n",
      "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (timestamp): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (relative_time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=16, out_features=128, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (timestamp): Linear(in_features=1, out_features=16, bias=True)\n",
      "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (static_context_variable_selection): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm_encoder): LSTM(64, 64, batch_first=True)\n",
      "  (lstm_decoder): LSTM(64, 64, batch_first=True)\n",
      "  (post_lstm_gate_encoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (post_lstm_gate_decoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_encoder): AddNorm(\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_decoder): AddNorm(\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (static_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (context): Linear(in_features=64, out_features=64, bias=False)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (multihead_attn): InterpretableMultiHeadAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (v_layer): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (q_layers): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "    (k_layers): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "    (attention): ScaledDotProductAttention(\n",
      "      (softmax): Softmax(dim=2)\n",
      "    )\n",
      "    (w_h): Linear(in_features=16, out_features=64, bias=False)\n",
      "  )\n",
      "  (post_attn_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pos_wise_ff): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_output_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# üöÄ Step 1: Define TFT model using the cleaned training dataset\n",
    "print(\"\\nüîπ Initializing TemporalFusionTransformer model with cleaned data...\")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset_cleaned,  # ‚úÖ Now using the CLEANED training dataset\n",
    "    learning_rate=0.001,  # Initial learning rate\n",
    "    hidden_size=64,  # LSTM hidden units\n",
    "    attention_head_size=4,  # Attention heads\n",
    "    dropout=0.1,  # Dropout for regularization\n",
    "    hidden_continuous_size=16,  # Hidden layer for continuous variables\n",
    "    loss=QuantileLoss(),  # ‚úÖ Using Quantile Loss\n",
    "    log_interval=10,  # Log progress every 10 steps\n",
    "    output_size=1,  # Single target variable (speed_meters_per_second)\n",
    "    reduce_on_plateau_patience=4  # Reduce LR if no improvement after 4 epochs\n",
    ")\n",
    "\n",
    "# üöÄ Step 2: Print model summary\n",
    "print(\"\\n‚úÖ TemporalFusionTransformer Model Initialized Successfully!\")\n",
    "print(tft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Starting Trainer Initialization...\n",
      "‚úÖ Trainer initialized successfully.\n",
      "‚úÖ Initializing TemporalFusionTransformer model...\n",
      "üîπ Encoder Reals: ['target']\n",
      "üîπ Decoder Reals: ['time']\n",
      "‚úÖ TFT model initialized.\n",
      "‚úÖ Wrapping model in TFTLightningModule...\n",
      "‚úÖ Model wrapped.\n",
      "\n",
      "üîπ Checking first batch from cleaned DataLoader before training...\n",
      "\n",
      "üîç Checking `train_dataset_cleaned` feature configuration...\n",
      "‚úÖ Successfully retrieved dataset parameters!\n",
      "   - Static Categoricals: ['vehicle']\n",
      "   - Time-Varying Reals Encoder: []\n",
      "   - Time-Varying Reals Decoder: []\n",
      "   - Target: speed_meters_per_second\n",
      "‚úÖ Cleaned DataLoaders created successfully!\n",
      "\n",
      "üîç Checking if train_dataloader_cleaned is properly initialized...\n",
      "   - DataLoader Length: 13306\n",
      "   - DataLoader dataset type: <class 'pytorch_forecasting.data.timeseries.TimeSeriesDataSet'>\n",
      "   - Dataset Length: 851585\n",
      "\n",
      "üîç Checking `train_dataset_cleaned` BEFORE DataLoader creation...\n",
      "‚ùå Error fetching first records from train_dataset_cleaned: slice indices must be integers or None or have an __index__ method\n",
      "\n",
      "üöÄ Attempting to fetch first batch...\n",
      "‚úÖ Successfully fetched batch 1\n",
      "‚ùå Error fetching batch: 'tuple' object has no attribute 'keys'\n",
      "\n",
      "üöÄ Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/issaennab/miniforge3/envs/tf_m1/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# ‚úÖ Step 1: Define the LightningModule wrapper for TFT\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model  # Assign the TFT model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_pred, _ = self.model(batch)  \n",
    "        loss = self.model.loss(y_pred, batch[\"encoder_target\"])  \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_pred, _ = self.model(batch)\n",
    "        loss = self.model.loss(y_pred, batch[\"encoder_target\"])  \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "print(\"‚úÖ Starting Trainer Initialization...\")\n",
    "\n",
    "# ‚úÖ Step 2: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"mps\" if torch.backends.mps.is_available() else \"cpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized successfully.\")\n",
    "\n",
    "# ‚úÖ Step 3: Define TFT Model (Fixing `reals` issue)\n",
    "print(\"‚úÖ Initializing TemporalFusionTransformer model...\")\n",
    "\n",
    "# üöÄ Extract column names from dataset dictionary\n",
    "try:\n",
    "    dataset_columns = list(train_dataset_cleaned.data.keys())  # ‚úÖ Get dictionary keys\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ERROR: Could not retrieve column names from dataset:\", e)\n",
    "    dataset_columns = []\n",
    "\n",
    "# üöÄ Define encoder/decoder variables (excluding `reals`)\n",
    "time_varying_reals_encoder = [\"target\"] if \"target\" in dataset_columns else []\n",
    "time_varying_reals_decoder = [\"time\"] if \"time\" in dataset_columns else []\n",
    "\n",
    "print(f\"üîπ Encoder Reals: {time_varying_reals_encoder}\")\n",
    "print(f\"üîπ Decoder Reals: {time_varying_reals_decoder}\")\n",
    "\n",
    "# ‚úÖ Create TemporalFusionTransformer model\n",
    "try:\n",
    "    tft_model = TemporalFusionTransformer.from_dataset(\n",
    "        train_dataset_cleaned,  # ‚úÖ Using the CLEANED dataset\n",
    "        learning_rate=0.001,\n",
    "        hidden_size=64,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.1,\n",
    "        loss=QuantileLoss(),\n",
    "        output_size=1,  \n",
    "        log_interval=10,\n",
    "        reduce_on_plateau_patience=4,\n",
    "        static_categoricals=[],  # ‚úÖ Ensure empty if no static categorical features\n",
    "        time_varying_reals_encoder=time_varying_reals_encoder,  # ‚úÖ Corrected\n",
    "        time_varying_reals_decoder=time_varying_reals_decoder,  # ‚úÖ Corrected\n",
    "    )\n",
    "    print(\"‚úÖ TFT model initialized.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ERROR: TFT Model Initialization Failed:\", e)\n",
    "    raise e\n",
    "\n",
    "# ‚úÖ Step 4: Wrap TFT in the LightningModule\n",
    "print(\"‚úÖ Wrapping model in TFTLightningModule...\")\n",
    "tft_lightning = TFTLightningModule(tft_model)\n",
    "print(\"‚úÖ Model wrapped.\")\n",
    "\n",
    "# ‚úÖ Step 5: Debug First Batch Before Training\n",
    "print(\"\\nüîπ Checking first batch from cleaned DataLoader before training...\")\n",
    "\n",
    "# ‚úÖ Define batch size\n",
    "BATCH_SIZE = 64  # Adjust based on memory constraints\n",
    "\n",
    "# üöÄ Checking the dataset feature configuration\n",
    "print(\"\\nüîç Checking `train_dataset_cleaned` feature configuration...\")\n",
    "\n",
    "try:\n",
    "    dataset_features = train_dataset_cleaned.get_parameters()  # ‚úÖ Fetch dataset parameters\n",
    "    print(\"‚úÖ Successfully retrieved dataset parameters!\")\n",
    "\n",
    "    # Print key settings to check if \"reals\" still exists\n",
    "    print(f\"   - Static Categoricals: {dataset_features.get('static_categoricals', [])}\")\n",
    "    print(f\"   - Time-Varying Reals Encoder: {dataset_features.get('time_varying_reals_encoder', [])}\")\n",
    "    print(f\"   - Time-Varying Reals Decoder: {dataset_features.get('time_varying_reals_decoder', [])}\")\n",
    "    print(f\"   - Target: {dataset_features.get('target', 'Not Specified')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error retrieving dataset parameters:\", e)\n",
    "    \n",
    "# ‚úÖ Create cleaned DataLoaders\n",
    "train_dataloader_cleaned = train_dataset_cleaned.to_dataloader(batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader_cleaned = val_dataset_cleaned.to_dataloader(batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ Cleaned DataLoaders created successfully!\")\n",
    "\n",
    "# ‚úÖ Check Before Iteration\n",
    "print(\"\\nüîç Checking if train_dataloader_cleaned is properly initialized...\")\n",
    "\n",
    "if hasattr(train_dataloader_cleaned, '__len__'):\n",
    "    print(f\"   - DataLoader Length: {len(train_dataloader_cleaned)}\")\n",
    "else:\n",
    "    print(\"   - ‚ùå Cannot determine DataLoader length!\")\n",
    "\n",
    "# ‚úÖ Check if dataset exists in DataLoader\n",
    "if hasattr(train_dataloader_cleaned, 'dataset'):\n",
    "    print(f\"   - DataLoader dataset type: {type(train_dataloader_cleaned.dataset)}\")\n",
    "    print(f\"   - Dataset Length: {len(train_dataloader_cleaned.dataset) if hasattr(train_dataloader_cleaned.dataset, '__len__') else 'Unknown'}\")\n",
    "else:\n",
    "    print(\"   - ‚ùå DataLoader has no dataset assigned!\")\n",
    "\n",
    "# ‚úÖ Print the first few items directly from train_dataset_cleaned BEFORE `.to_dataloader()`\n",
    "print(\"\\nüîç Checking `train_dataset_cleaned` BEFORE DataLoader creation...\")\n",
    "\n",
    "try:\n",
    "    first_items = train_dataset_cleaned[:5]  # Try fetching first 5 records\n",
    "    print(\"‚úÖ Successfully fetched first items from train_dataset_cleaned:\")\n",
    "    print(first_items)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error fetching first records from train_dataset_cleaned:\", e)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     print(\"\\nüöÄ Attempting to fetch first batch...\")\n",
    "#     for i, batch in enumerate(train_dataloader_cleaned):\n",
    "#         print(f\"‚úÖ Successfully fetched batch {i+1}\")\n",
    "#         print(\"üîπ Batch Keys:\", batch.keys())\n",
    "\n",
    "#         for key, value in batch.items():\n",
    "#             print(f\"   üîπ {key}: Shape = {value.shape if isinstance(value, torch.Tensor) else type(value)}\")\n",
    "        \n",
    "#         break  # Only print first batch\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"‚ùå Error fetching batch:\", e)\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Step 6: Train the Model\n",
    "print(\"\\nüöÄ Training model...\")\n",
    "\n",
    "try:\n",
    "    trainer.fit(\n",
    "        model=tft_lightning,  \n",
    "        train_dataloaders=train_dataloader_cleaned,  # ‚úÖ Using cleaned DataLoader\n",
    "        val_dataloaders=val_dataloader_cleaned,\n",
    "    )\n",
    "    print(\"‚úÖ Training complete.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Training failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer (TFT) Model Findings  \n",
    "\n",
    "## Challenges Encountered  \n",
    "- **High Computational Requirements**: TFT requires a **large amount of memory and processing power**, making it challenging to train efficiently on our dataset.  \n",
    "- **Sensitivity to Data Quality**: TFT is highly dependent on **clean, structured sequential data**, and any missing values or inconsistencies **significantly impact training stability**.  \n",
    "- **Training Complexity**: Unlike LSTMs/GRUs, **TFT needs careful tuning** of hyperparameters, leading to longer experimentation times.  \n",
    "\n",
    "## Final Decision  \n",
    "Due to the **computational cost and sensitivity**, TFT was not fully trained for deployment, but **remains a strong candidate for future research** if given more time and resources.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau Dashboard Overview\n",
    "\n",
    "## Purpose  \n",
    "The **Tableau Dashboard** serves as an interactive visualization tool to compare the performance of different machine learning models (GRU, LSTM) in predicting **road conditions** based on vehicle sensor data.  \n",
    "\n",
    "## Key Features  \n",
    "- **Time-Series Visualization**: Displays probability trends for different road conditions (Asphalt, Cobblestone, Dirt) for both GRU and LSTM models.  \n",
    "- **Interactivity**: Users can filter by vehicle type, scenario, and road conditions to analyze performance across different conditions.  \n",
    "- **Comparative Analysis**: Side-by-side plots allow for direct comparisons between GRU and LSTM models.  \n",
    "- **KPIs**: Displays **average confidence scores** for both models and identifies the most frequently predicted road condition.  \n",
    "\n",
    "## Insights  \n",
    "- GRU and LSTM show similar prediction trends, but **GRU exhibited slightly higher confidence** in some scenarios.  \n",
    "- Filtering by individual vehicles allows for **detailed per-vehicle analysis** of road condition predictions.  \n",
    "- The dashboard serves as an effective tool for model evaluation, data exploration, and potential real-world applications.  \n",
    "\n",
    "## Tableau Dashboard\n",
    "\n",
    "<img src=\"../docs/tableau-dashboard.png\" alt=\"Image Description\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Future Work & Real-World Applications  \n",
    "\n",
    "## üîÑ Potential Enhancements  \n",
    "- **Refining Data Cleaning**: Improve feature engineering for better model performance and accuracy.  \n",
    "- **Adding More Sensors**: Integrating additional sensors like **brake pressure, suspension type,** and **road friction** could lead to **more precise terrain classification**.  \n",
    "- **Exploring Additional ML Models**: Future iterations can explore **TFT**, **hybrid models**, and **attention-based architectures** to enhance predictive accuracy.  \n",
    "- **Extending the Dataset**: Expanding the dataset to include **more diverse road types, environmental conditions, and extreme terrains** for better generalization.  \n",
    "\n",
    "## üåç Real-World Applications  \n",
    "- **üöß City Infrastructure & Road Maintenance**  \n",
    "  - The predicted road condition data could be integrated into **smart city IoT systems** to help **detect road damage** and **schedule maintenance proactively**.  \n",
    "- **üöó Vehicle & Tire Optimization**  \n",
    "  - By analyzing vehicle behavior on different terrains, **automakers** can recommend **optimized tires and suspension settings** for enhanced **stability and safety**.  \n",
    "- **ü§ñ Autonomous Vehicles**  \n",
    "  - Road condition predictions can help **self-driving cars** adjust their driving patterns dynamically based on real-time road feedback, improving adaptability and safety.  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Final Thoughts**\n",
    "This project demonstrates **not only predictive modeling** but also **real-world applications** in:  \n",
    "‚úÖ **Smart Infrastructure Development & Road Safety**  \n",
    "‚úÖ **Connected Vehicle Systems & IoT Integration**  \n",
    "‚úÖ **Optimized Vehicle Performance & Manufacturing Insights**  \n",
    "\n",
    "With **continued refinement** and **future iterations**, this project has **the potential to revolutionize road safety, infrastructure planning, and autonomous vehicle intelligence**. üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
